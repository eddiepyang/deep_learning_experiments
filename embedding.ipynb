{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import json\n",
    "import zipfile as zip\n",
    "\n",
    "import spacy\n",
    "from keras.preprocessing import text, sequence\n",
    "from gensim import corpora\n",
    "from gensim.models import tfidfmodel\n",
    "from gensim.matutils import corpus2csc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "from collections import Counter, OrderedDict\n",
    "from os.path import expanduser\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras import models, optimizers, regularizers\n",
    "from keras.layers import Dropout, Dense, Activation, Flatten, LSTM, \\\n",
    "Conv1D, Conv2D, MaxPooling1D, GRU, Embedding, CuDNNLSTM, Bidirectional\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is preprocessed as a list of lists, reviews are parsed and stop words and punctuation are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./processed/processed.txt', 'r') as f:\n",
    "  restaurants = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different text cleaning for reviews\n",
    "with open('./processed/reviews_cleaned.txt', 'r') as f:\n",
    "  reviews = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras text processing example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer()\n",
    "tokenizer.fit_on_texts(['eat a lot, need to exercise more', \"vegetables are good\", \"who likes chicken all the time\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eat': 1,\n",
       " 'a': 2,\n",
       " 'lot': 3,\n",
       " 'need': 4,\n",
       " 'to': 5,\n",
       " 'exercise': 6,\n",
       " 'more': 7,\n",
       " 'vegetables': 8,\n",
       " 'are': 9,\n",
       " 'good': 10,\n",
       " 'who': 11,\n",
       " 'likes': 12,\n",
       " 'chicken': 13,\n",
       " 'all': 14,\n",
       " 'the': 15,\n",
       " 'time': 16}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6, 7], [13]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(['eat a lot', 'need to exercise more', 'chicken'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing the same process with gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Skipping a step by not creating two dictionaries for train and test, they get recombined anyway for an update of new data though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary\n",
    "# dict_yelp = corpora.Dictionary(reviews)\n",
    "\n",
    "# # re-rerun after filtering dictionary\n",
    "# corpus = [dict_yelp.doc2bow(review) for review in reviews]\n",
    "\n",
    "# # save corpus\n",
    "# corpora.MmCorpus.serialize('./processed/corpus.mm', corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = False\n",
    "if bow:\n",
    "    # load corpus\n",
    "    corpus = corpora.MmCorpus('./processed/corpus.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_yelp.save('./processed/dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_yelp = corpora.Dictionary.load('./processed/dictionary')\n",
    "\n",
    "# tune corpus to get a smaller dictionary and doc_term matrix, embeddings will still work but bow will not fit into 8gb gpu memory otherwise\n",
    "dict_yelp.filter_extremes(no_below=40, keep_n=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 240115),\n",
       " ('but', 234529),\n",
       " ('with', 212575),\n",
       " ('place', 204032),\n",
       " ('that', 201558),\n",
       " ('on', 194653),\n",
       " ('do', 176703),\n",
       " ('go', 167435),\n",
       " ('so', 159652),\n",
       " ('service', 155644),\n",
       " ('get', 152298),\n",
       " ('great', 151777),\n",
       " ('at', 146103),\n",
       " ('here', 139643),\n",
       " ('will', 131348),\n",
       " ('very', 126403),\n",
       " ('time', 124857),\n",
       " ('come', 122212),\n",
       " ('there', 121375),\n",
       " ('like', 119441),\n",
       " ('order', 117927),\n",
       " ('if', 115701),\n",
       " ('would', 115030),\n",
       " ('all', 113190),\n",
       " ('as', 112922),\n",
       " ('back', 110512),\n",
       " ('just', 109932),\n",
       " ('out', 109830),\n",
       " ('try', 102538),\n",
       " ('one', 101402)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most common words\n",
    "top_ids = sorted(dict_yelp.dfs.items(), key=lambda x: x[1], reverse=True)[0:30]\n",
    "[(dict_yelp[item[0]], item[1]) for item in top_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_sequencer(dictionary, text, max_len=200):\n",
    "    \n",
    "    processed = []\n",
    "    # in case the word is not in the dictionary because it was filtered out use this number to represent an out of set id \n",
    "    dict_final = len(dictionary.keys()) + 1\n",
    "    \n",
    "    for word in text:        \n",
    "        if word in dictionary.token2id.keys():\n",
    "    # remember the ids have an offset of 1 for this because 0 represents a padded value        \n",
    "            processed.append(dictionary.token2id[word] + 1) \n",
    "        else:\n",
    "            processed.append(dict_final)\n",
    "    \n",
    "    return processed[0:max_len]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 6.44 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "save = False\n",
    "if save:\n",
    "    \n",
    "    corpus = [text_sequencer(dict_yelp, review) for review in reviews]\n",
    "    corpus = sequence.pad_sequences(corpus, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the converted corpus array, not from gensim\n",
    "if save:\n",
    "    np.save('./processed/corpus.npy', corpus)\n",
    "    \n",
    "corpus = np.load('./processed/corpus.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # no sorting\n",
    "# def data_split(data, proportion = .2):\n",
    "#     cutoff = round(len(data) * (1-proportion))\n",
    "#     return data[0:cutoff], data[cutoff:]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_path = '/projects/embeddings/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings():\n",
    "    # load glove vectors\n",
    "    embeddings_index={}\n",
    "    with zip.ZipFile(expanduser(\"~\")+ emb_path +'glove.6B.zip', 'r') as f:\n",
    "        with f.open('glove.6B.100d.txt', 'r') as z:\n",
    "            for line in z:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                coefs = np.asarray(values[1:], dtype='float32')\n",
    "                embeddings_index[word] = coefs\n",
    "    \n",
    "    return embeddings_index\n",
    "\n",
    "def id_to_glove(keys, dict_yelp):\n",
    "    \n",
    "    embeddings_index = load_embeddings()\n",
    "    conversion_table = {}\n",
    "    for key in keys:\n",
    "        if bytes(key, 'utf-8') in embeddings_index.keys():\n",
    "            conversion_table[dict_yelp.token2id[key]+1] = embeddings_index[bytes(key, 'utf-8')]\n",
    "        else:\n",
    "            conversion_table[dict_yelp.token2id[key]+1] = np.random.randn(100)\n",
    "    return conversion_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 s, sys: 153 ms, total: 15.5 s\n",
      "Wall time: 15.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conversion_table = id_to_glove(dict_yelp.token2id.keys(), dict_yelp)\n",
    "embedding_matrix = np.vstack([conversion_table[key] for key in conversion_table.keys()])\n",
    "embedding_matrix = np.vstack((np.zeros(100), embedding_matrix, np.random.randn(100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressed matrix creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bow:\n",
    "    # skipped if not using bag-of-words or corpus fits into memory, uses gensim corpus object not list of lists\n",
    "    matrix = corpus2csc(corpus, num_terms=len(dict_yelp.keys()), num_docs=490049, dtype=np.int16).T\n",
    "    matrix = matrix.tocsr()\n",
    "    matrix.shape\n",
    "if save:\n",
    "    scipy.sparse.save_npz('./processed/corpus_matrix', matrix)\n",
    "\n",
    "# matrix = scipy.sparse.load_npz('./processed/corpus_matrix.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rating(rating):\n",
    "    if rating in [4,5]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = np.array([restaurant['stars'] for restaurant in restaurants])\n",
    "stars = [convert_rating(star) for star in stars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ratings.npy', 'rb') as f:\n",
    "    stars = np.load(f, allow_pickle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, train_y, val_y = train_test_split(corpus, stars, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x = stars, y = stars, estimator=lambda x: len(x)/len(stars))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras needs arrays as inputs, so .A reconverts a batch to the original numpy array\n",
    "\n",
    "def get_batch(matrix, labels, bs):\n",
    "    # matrix should be a document x word csr matrix\n",
    "    i = 0\n",
    "    while i < matrix.shape[0]/bs:\n",
    "        yield matrix[i*bs:(i+1)*bs,].A, labels[i*bs:(i+1)*bs]\n",
    "        i+=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bow:\n",
    "    generator = get_batch(matrix, stars, 32)\n",
    "    review_lens = [len(review) for review in reviews]\n",
    "    print(np.max(review_lens))\n",
    "    print(np.min(review_lens))\n",
    "    print(np.std(review_lens))\n",
    "    print(np.median(review_lens))\n",
    "    print(np.mean(review_lens))\n",
    "    print(np.percentile(review_lens, 99.5))\n",
    "    sns.distplot(review_lens)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally written to cut review lengths, did this in gensim_walkthrough instead\n",
    "def cut(review, cutoff=30):\n",
    "    text = ''\n",
    "    for i, word in enumerate(review):\n",
    "        if i <= 30:\n",
    "            if text == '':\n",
    "                text = word\n",
    "            else:    \n",
    "                text += ' ' + word\n",
    "    return text        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use if training for more categories\n",
    "vocab_size = len(dict_yelp.keys())\n",
    "assert corpus.shape == (490049, 200)\n",
    "stars_cat = to_categorical(stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    with open('ratings.npy', 'wb') as f:\n",
    "        np.save(f, stars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 100)          1258000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 196, 100)          50100     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 194, 100)          30100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 48, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 67)                45024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 68        \n",
      "=================================================================\n",
      "Total params: 1,383,292\n",
      "Trainable params: 1,383,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# units for output size in Dense layer, vocab_size for number of features in nlp in Embedding \n",
    "# tried adding dropout but it lowered accuracy, shouldn't need it if it's not overfitting\n",
    "def get_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(Embedding(len(embedding_matrix), 100, input_length=200,  embeddings_regularizer=regularizers.l2(1e-6), weights = [embedding_matrix]))\n",
    "    model.add(Conv1D(100, 5))\n",
    "    model.add(Conv1D(100, 3))\n",
    "    model.add(MaxPooling1D(4))\n",
    "    model.add(LSTM(67))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model2():\n",
    "    model = models.Sequential()\n",
    "    model.add(Embedding(len(embedding_matrix), 100, input_length=200,  embeddings_regularizer=regularizers.l2(1e-6), weights = [embedding_matrix]))\n",
    "    model.add(Bidirectional(CuDNNLSTM(67, return_sequences = True)))\n",
    "    model.add(Bidirectional(CuDNNLSTM(67)))\n",
    "    model.add(Dense(31))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model3():\n",
    "    model = models.Sequential()\n",
    "    model.add(Embedding(len(embedding_matrix), 100, input_length=200,  embeddings_regularizer=regularizers.l2(1e-6), weights = [embedding_matrix]))\n",
    "    model.add(CuDNNLSTM(67))\n",
    "    model.add(Dense(31))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam, loss='binary_crossentropy', metrics=['binary_crossentropy', 'accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 200, 100)          1258000   \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_6 (CuDNNLSTM)     (None, 67)                45292     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 31)                2108      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 32        \n",
      "=================================================================\n",
      "Total params: 1,305,432\n",
      "Trainable params: 1,305,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 313631 samples, validate on 78408 samples\n",
      "Epoch 1/2\n",
      "313631/313631 [==============================] - 21s 67us/step - loss: 0.7669 - binary_crossentropy: 0.4134 - acc: 0.8044 - val_loss: 0.6898 - val_binary_crossentropy: 0.3525 - val_acc: 0.8441\n",
      "Epoch 2/2\n",
      "313631/313631 [==============================] - 20s 65us/step - loss: 0.6552 - binary_crossentropy: 0.3265 - acc: 0.8575 - val_loss: 0.6369 - val_binary_crossentropy: 0.3158 - val_acc: 0.8635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efcf1975f60>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, train_y, batch_size=500, epochs=2, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reset weights if necessary\n",
    "# model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust lr since val loss increases, seems to be going past minimum\n",
    "K.set_value(model.optimizer.lr, 0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 313631 samples, validate on 78408 samples\n",
      "Epoch 1/1\n",
      "313631/313631 [==============================] - 20s 64us/step - loss: 0.5990 - binary_crossentropy: 0.2958 - acc: 0.8727 - val_loss: 0.5940 - val_binary_crossentropy: 0.2961 - val_acc: 0.8736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efcf15bdd30>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, train_y, batch_size=500, epochs=1, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    model.save('./models/lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model = load_model('./models/test_ann')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98010/98010 [==============================] - 20s 206us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.596296247358578, 0.2983358464220594, 0.8721048872515372]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val, val_y, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'binary_crossentropy', 'acc']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val, val_y, regression = False):\n",
    "    \n",
    "        \n",
    "    preds = model.predict(val)\n",
    "    #idx = np.random.randint(0, len(val_y), 5000)\n",
    "    pred_err = np.subtract(val_y.astype('float32'), preds.reshape(-1))\n",
    "    sns.distplot(pred_err)\n",
    "    plt.show()\n",
    "   \n",
    "    if regression:\n",
    "        rmse = np.sqrt(np.mean(pred_err**2))\n",
    "        print('rmse : %.4f' % rmse)\n",
    "    else:\n",
    "        cond_error = round((abs(pred_err) >= 0.5).sum()/len(pred_err), 4)\n",
    "        binary_cross_entropy = np.mean(\n",
    "                                        val_y * np.log(preds.reshape(-1)) + \\\n",
    "                                       (1-val_y) * np.log(1-preds.reshape(-1))\n",
    "        ) \n",
    "    \n",
    "        print('prob error is greater than 0.5 is %.4f' % cond_error)\n",
    "        print('binary cross entropy is %.4f' % binary_cross_entropy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryeyoo/anaconda3/envs/keras/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob error is greater than 0.5 is 0.1279\n",
      "binary cross entropy is -0.2983\n"
     ]
    }
   ],
   "source": [
    "evaluate(val, val_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
