{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import json\n",
    "import zipfile as zip\n",
    "\n",
    "import spacy\n",
    "from keras.preprocessing import text, sequence\n",
    "from gensim import corpora\n",
    "from gensim.models import tfidfmodel\n",
    "from gensim.matutils import corpus2csc\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "from collections import Counter, OrderedDict\n",
    "from os.path import expanduser\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras import models, optimizers, regularizers\n",
    "from keras.layers import Dropout, Dense, Activation, Flatten, LSTM, \\\n",
    "Conv1D, MaxPooling1D, GRU, Embedding, CuDNNLSTM, Bidirectional\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is preprocessed as a list of lists, reviews are parsed and stop words and punctuation are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_run = False\n",
    "\n",
    "if re_run:\n",
    "    # processed from gensim_walkthrough notebook\n",
    "    with open('../../data/processed/processed.txt', 'r') as f:\n",
    "        restaurants = tuple(json.loads(line) for line in f)\n",
    "\n",
    "    # different text cleaning for reviews\n",
    "    with open('../../data/processed/reviews_cleaned.txt', 'r') as f:\n",
    "        reviews = tuple(json.loads(line) for line in f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras text processing example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if re_run:\n",
    "    tokenizer = text.Tokenizer()\n",
    "    tokenizer.fit_on_texts(reviews[0])\n",
    "    tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing the same process with gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skipping a step by not creating two dictionaries for train and test, they get recombined anyway for an update of new data though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000\n",
      "CPU times: user 1.19 ms, sys: 7.7 ms, total: 8.89 ms\n",
      "Wall time: 7.88 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if re_run:\n",
    "    \n",
    "    # create dictionary\n",
    "    dict_yelp = corpora.Dictionary(reviews)\n",
    "    # tune corpus to get a smaller dictionary and therefore a smaller doc_term matrix, \n",
    "    # embeddings will still work but bow will not fit into 8gb gpu otherwise\n",
    "    dict_yelp.filter_extremes(no_below=10, keep_n=13000)\n",
    "    dict_yelp.save('../../data/processed/dictionary')\n",
    "\n",
    "else:\n",
    "    \n",
    "    dict_yelp = corpora.Dictionary.load('../../data/processed/dictionary')\n",
    "\n",
    "print(len(dict_yelp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if re_run:\n",
    "    # most common words\n",
    "    top_ids = sorted(dict_yelp.dfs.items(), key=lambda x: x[1], reverse=True)[0:30]\n",
    "    [(dict_yelp[item[0]], item[1]) for item in top_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_sequencer(dictionary, text, max_len=200):\n",
    "    \n",
    "    processed = []\n",
    "    # in case the word is not in the dictionary because it was filtered out use this number to represent an out of set id \n",
    "    dict_final = len(dictionary.keys()) + 1\n",
    "    \n",
    "    for word in text:        \n",
    "        if word in dictionary.token2id.keys():\n",
    "    # remember the ids have an offset of 1 for this because 0 represents a padded value        \n",
    "            processed.append(dictionary.token2id[word] + 1) \n",
    "        else:\n",
    "            processed.append(dict_final)\n",
    "    \n",
    "    return processed[0:max_len]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.26 s, sys: 482 ms, total: 2.74 s\n",
      "Wall time: 2.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if re_run:\n",
    "    \n",
    "    corpus = tuple(text_sequencer(dict_yelp, review) for review in reviews)\n",
    "    corpus = sequence.pad_sequences(corpus, maxlen=200)\n",
    "    assert corpus.shape == (490049, 200)\n",
    "    # this is the converted corpus array, not bow\n",
    "    np.save('../../data/processed/corpus.npy', corpus)\n",
    "\n",
    "else:\n",
    "    corpus = np.load('../../data/processed/corpus.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(emb_path = '/projects/embeddings/data/'):\n",
    "    # load glove vectors\n",
    "    embeddings_index={}\n",
    "    with zip.ZipFile(expanduser(\"~\")+ emb_path +'glove.6B.zip', 'r') as f:\n",
    "        with f.open('glove.6B.100d.txt', 'r') as z:\n",
    "            for line in z:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                coefs = np.asarray(values[1:], dtype='float32')\n",
    "                embeddings_index[word] = coefs\n",
    "    \n",
    "    return embeddings_index\n",
    "\n",
    "def id_to_glove(keys, dict_yelp):\n",
    "    \n",
    "    embeddings_index = load_embeddings()\n",
    "    conversion_table = {}\n",
    "    for key in keys:\n",
    "        if bytes(key, 'utf-8') in embeddings_index.keys():\n",
    "            conversion_table[dict_yelp.token2id[key]+1] = embeddings_index[bytes(key, 'utf-8')]\n",
    "        else:\n",
    "            conversion_table[dict_yelp.token2id[key]+1] = np.random.randn(100)\n",
    "    return conversion_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.5 s, sys: 209 ms, total: 16.7 s\n",
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conversion_table = id_to_glove(dict_yelp.token2id.keys(), dict_yelp)\n",
    "embedding_matrix= np.vstack(conversion_table.values())\n",
    "embedding_matrix = np.vstack((np.zeros(100), embedding_matrix, np.random.randn(100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rating(rating):\n",
    "    if rating in [4,5]:\n",
    "        return 1\n",
    "    elif rating in [1,2]:\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_rating_set(corpus, stars):\n",
    "    \n",
    "    \n",
    "    mids = set()\n",
    "    \n",
    "    def get_mids():\n",
    "\n",
    "        for i, rating in enumerate(stars):\n",
    "            if rating is None:\n",
    "                mids.add(i)\n",
    "    \n",
    "    get_mids()\n",
    "    filtered_corpus, filtered_stars = [], []\n",
    "    \n",
    "    for i in range(len(corpus)):\n",
    "        if i in mids:\n",
    "            next\n",
    "        else:\n",
    "            filtered_corpus.append(corpus[i]), filtered_stars.append(stars[i])\n",
    "    \n",
    "    return filtered_corpus, filtered_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if re_run:\n",
    "    stars = [convert_rating(restaurant['stars']) for restaurant in restaurants]\n",
    "    data, lab = get_rating_set(corpus, stars)\n",
    "    with open('../../data/numpy/ratings.npy', 'wb') as outf:\n",
    "        np.save(outf, lab)\n",
    "    with open('../../data/numpy/corpus.npy', 'wb') as outf:\n",
    "        np.save(outf, data)\n",
    "else:\n",
    "    data, lab = np.load('../../data/numpy/corpus.npy'), np.load('../../data/numpy/ratings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, train_y, val_y = train_test_split(data, lab, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryeyoo/miniconda3/envs/keras/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADQFJREFUeJzt3V+Infldx/H3pwnxQouIOYLkzybotBDa4tIxCoJW3YUEIRFcJQGxC6uDYKy4UsyiRIlXbsW9ykUjLlZhm8a90FFGAtqKf+iWmdWldRKiQ6zNIRc73W4rIjYd/XqRSTl79iTnOTNn9iS/vF8wcH7P8+M534vhzcNJzjOpKiRJbXnXrAeQJE2fcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWrQ7lm98d69e+vQoUOzentJeii9+uqrX66q3rh9M4v7oUOHWFlZmdXbS9JDKcl/dNnnxzKS1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1KCZfUNVatmXzr9/1iPoAXTw3Bfesffyzl2SGmTcJalBxl2SGmTcJalBxl2SGmTcJalBxl2SGmTcJalBxl2SGmTcJalBneKe5FiS60nWkpwdcf6FJK9t/vxrkq9Of1RJUldjny2TZBdwAXgS6APLSRar6urdPVX1qwP7fxl4fAdmlSR11OXO/SiwVlU3quo2cAk4eZ/9p4FPTmM4SdLWdIn7PuDmwLq/eextkjwGHAY+fY/zC0lWkqysr69POqskqaMucc+IY3WPvaeAl6vqf0edrKqLVTVfVfO9Xq/rjJKkCXWJex84MLDeD9y6x95T+JGMJM1cl7gvA3NJDifZw52ALw5vSvJe4DuAz053REnSpMbGvao2gDPAFeAacLmqVpOcT3JiYOtp4FJV3esjG0nSO6TTn9mrqiVgaejYuaH1b09vLEnSdvgNVUlqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAZ1inuSY0muJ1lLcvYee34mydUkq0lemu6YkqRJjP0bqkl2AReAJ4E+sJxksaquDuyZA54Dfqiq3kzyXTs1sCRpvC537keBtaq6UVW3gUvAyaE9vwBcqKo3Aarq9emOKUmaRJe47wNuDqz7m8cGvQd4T5J/TPJKkmPTGlCSNLmxH8sAGXGsRlxnDvgQsB/4+yTvq6qvvuVCyQKwAHDw4MGJh5UkddPlzr0PHBhY7wdujdjz51X1jar6d+A6d2L/FlV1sarmq2q+1+ttdWZJ0hhd4r4MzCU5nGQPcApYHNrzZ8CPAiTZy52PaW5Mc1BJUndj415VG8AZ4ApwDbhcVatJzic5sbntCvBGkqvAZ4CPVtUbOzW0JOn+unzmTlUtAUtDx84NvC7g2c0fSdKM+Q1VSWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWpQp7gnOZbkepK1JGdHnH86yXqS1zZ/fn76o0qSuhr7B7KT7AIuAE8CfWA5yWJVXR3a+qmqOrMDM0qSJtTlzv0osFZVN6rqNnAJOLmzY0mStqNL3PcBNwfW/c1jw34qyeeTvJzkwKgLJVlIspJkZX19fQvjSpK66BL3jDhWQ+u/AA5V1QeAvwY+MepCVXWxquarar7X6002qSSpsy5x7wODd+L7gVuDG6rqjar6+ubyD4APTmc8SdJWdIn7MjCX5HCSPcApYHFwQ5LvHlieAK5Nb0RJ0qTG/m+ZqtpIcga4AuwCXqyq1STngZWqWgQ+kuQEsAF8BXh6B2eWJI0xNu4AVbUELA0dOzfw+jnguemOJknaKr+hKkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1KBOcU9yLMn1JGtJzt5n31NJKsn89EaUJE1qbNyT7AIuAMeBI8DpJEdG7Hs38BHgc9MeUpI0mS537keBtaq6UVW3gUvAyRH7fgd4HvifKc4nSdqCLnHfB9wcWPc3j31TkseBA1X1l1OcTZK0RV3inhHH6psnk3cBLwC/NvZCyUKSlSQr6+vr3aeUJE2kS9z7wIGB9X7g1sD63cD7gL9N8kXgB4HFUf+oWlUXq2q+quZ7vd7Wp5Yk3VeXuC8Dc0kOJ9kDnAIW756sqq9V1d6qOlRVh4BXgBNVtbIjE0uSxhob96raAM4AV4BrwOWqWk1yPsmJnR5QkjS53V02VdUSsDR07Nw99n5o+2NJkrbDb6hKUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoM6xT3JsSTXk6wlOTvi/C8m+UKS15L8Q5Ij0x9VktTV2Lgn2QVcAI4DR4DTI+L9UlW9v6q+D3ge+P2pTypJ6qzLnftRYK2qblTVbeAScHJwQ1X958DyW4Ga3oiSpEnt7rBnH3BzYN0HfmB4U5JfAp4F9gA/NupCSRaABYCDBw9OOqskqaMud+4Zcextd+ZVdaGqvgf4deA3R12oqi5W1XxVzfd6vckmlSR11iXufeDAwHo/cOs++y8BP7mdoSRJ29Ml7svAXJLDSfYAp4DFwQ1J5gaWPwH82/RGlCRNauxn7lW1keQMcAXYBbxYVatJzgMrVbUInEnyBPAN4E3gwzs5tCTp/rr8gypVtQQsDR07N/D6V6Y8lyRpG/yGqiQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1qNM3VB9UH/zoH896BD2AXv3Yz816BGnmvHOXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqUKe4JzmW5HqStSRnR5x/NsnVJJ9P8jdJHpv+qJKkrsbGPcku4AJwHDgCnE5yZGjbPwPzVfUB4GXg+WkPKknqrsud+1FgrapuVNVt4BJwcnBDVX2mqv57c/kKsH+6Y0qSJtEl7vuAmwPr/uaxe3kG+KvtDCVJ2p4uDw7LiGM1cmPys8A88CP3OL8ALAAcPHiw44iSpEl1uXPvAwcG1vuBW8ObkjwB/AZwoqq+PupCVXWxquarar7X621lXklSB13ivgzMJTmcZA9wClgc3JDkceDj3An769MfU5I0ibFxr6oN4AxwBbgGXK6q1STnk5zY3PYx4NuAP03yWpLFe1xOkvQO6PTHOqpqCVgaOnZu4PUTU55LkrQNfkNVkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhrUKe5JjiW5nmQtydkR5384yT8l2Ujy1PTHlCRNYmzck+wCLgDHgSPA6SRHhrZ9CXgaeGnaA0qSJre7w56jwFpV3QBIcgk4CVy9u6Gqvrh57v92YEZJ0oS6fCyzD7g5sO5vHptYkoUkK0lW1tfXt3IJSVIHXeKeEcdqK29WVRerar6q5nu93lYuIUnqoEvc+8CBgfV+4NbOjCNJmoYucV8G5pIcTrIHOAUs7uxYkqTtGBv3qtoAzgBXgGvA5apaTXI+yQmAJN+fpA/8NPDxJKs7ObQk6f66/G8ZqmoJWBo6dm7g9TJ3Pq6RJD0A/IaqJDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSgzrFPcmxJNeTrCU5O+L8tyT51Ob5zyU5NO1BJUndjY17kl3ABeA4cAQ4neTI0LZngDer6nuBF4DfnfagkqTuuty5HwXWqupGVd0GLgEnh/acBD6x+fpl4MeTZHpjSpIm0SXu+4CbA+v+5rGRe6pqA/ga8J3TGFCSNLndHfaMugOvLewhyQKwsLn8ryTXO7y/utkLfHnWQzwI8nsfnvUIeit/N+/6ral8oPFYl01d4t4HDgys9wO37rGnn2Q38O3AV4YvVFUXgYtdBtNkkqxU1fys55CG+bs5G10+llkG5pIcTrIHOAUsDu1ZBO7eLj0FfLqq3nbnLkl6Z4y9c6+qjSRngCvALuDFqlpNch5YqapF4A+BP0myxp079lM7ObQk6f7iDXYbkixsfuwlPVD83ZwN4y5JDfLxA5LUIOP+kBv3aAhpVpK8mOT1JP8y61keRcb9Idbx0RDSrPwRcGzWQzyqjPvDrcujIaSZqKq/Y8T3XfTOMO4Pty6PhpD0CDLuD7dOj32Q9Ogx7g+3Lo+GkPQIMu4Pty6PhpD0CDLuD7HNxyvffTTENeByVa3OdirpjiSfBD4LvDdJP8kzs57pUeI3VCWpQd65S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNej/Af4dEpiBLXZFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x = lab, y = lab, estimator=lambda x: len(x)/len(lab))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(dict_yelp)\n",
    "Adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# units for output size in Dense layer, vocab_size for number of features in nlp in Embedding \n",
    "# tried adding dropout but it lowered accuracy, shouldn't need it if it's not overfitting\n",
    "def get_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(Embedding(len(embedding_matrix), 100, input_length=200,  embeddings_regularizer=regularizers.l2(1e-6), weights = [embedding_matrix]))\n",
    "    model.add(Conv1D(100, 5))\n",
    "    model.add(Conv1D(100, 3))\n",
    "    model.add(MaxPooling1D(4))\n",
    "    model.add(LSTM(67))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model2():\n",
    "    model = models.Sequential()\n",
    "    model.add(Embedding(len(embedding_matrix), 100, input_length=200,  embeddings_regularizer=regularizers.l2(1e-6), weights = [embedding_matrix]))\n",
    "    model.add(Bidirectional(CuDNNLSTM(67, return_sequences = True)))\n",
    "    model.add(Bidirectional(CuDNNLSTM(67)))\n",
    "    model.add(Dense(31))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model3():\n",
    "    model = models.Sequential()\n",
    "    model.add(Embedding(len(embedding_matrix), 100, input_length=200,  embeddings_regularizer=regularizers.l2(1e-6), weights = [embedding_matrix]))\n",
    "    #model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(CuDNNLSTM(67))\n",
    "    model.add(Dense(31))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['binary_crossentropy', 'accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import merge\n",
    "from keras.layers.core import *\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class ScaledDotProductAttention(keras.layers.Layer):\n",
    "    \"\"\"The attention layer that takes three inputs representing queries, keys and values.\n",
    "\n",
    "    \\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{Q K^T}{\\sqrt{d_k}}) V\n",
    "\n",
    "    See: https://arxiv.org/pdf/1706.03762.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 return_attention=False,\n",
    "                 history_only=False,\n",
    "                 **kwargs):\n",
    "        \"\"\"Initialize the layer.\n",
    "\n",
    "        :param return_attention: Whether to return attention weights.\n",
    "        :param history_only: Whether to only use history data.\n",
    "        :param kwargs: Arguments for parent class.\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        self.history_only = history_only\n",
    "        super(ScaledDotProductAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'return_attention': self.return_attention,\n",
    "            'history_only': self.history_only,\n",
    "        }\n",
    "        base_config = super(ScaledDotProductAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_attention:\n",
    "            return [input_shape[-1], input_shape[0][:2] + (input_shape[1][1],)]\n",
    "        return input_shape[-1]\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[-1]\n",
    "        if self.return_attention:\n",
    "            return [mask, None]\n",
    "        return mask\n",
    "\n",
    "    def call(self, inputs, mask=None, **kwargs):\n",
    "        query, key, value = inputs\n",
    "        feature_dim = K.shape(query)[-1]\n",
    "        e = K.batch_dot(query, key, axes=2) / K.sqrt(K.cast(feature_dim, dtype=K.floatx()))\n",
    "        if self.history_only:\n",
    "            query_len, key_len = K.shape(query)[1], K.shape(key)[1]\n",
    "            ones = tf.ones((query_len, key_len))\n",
    "            e -= (ones - tf.matrix_band_part(ones, -1, 0)) * 1e9\n",
    "        if isinstance(mask, list) and mask[-1] is not None:\n",
    "            e -= (1.0 - K.cast(K.expand_dims(mask[-1], axis=-2), K.floatx())) * 1e9\n",
    "        a = keras.activations.softmax(e)\n",
    "        v = K.batch_dot(a, value)\n",
    "        if self.return_attention:\n",
    "            return [v, a]\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class SeqSelfAttention(keras.layers.Layer):\n",
    "\n",
    "    ATTENTION_TYPE_ADD = 'additive'\n",
    "    ATTENTION_TYPE_MUL = 'multiplicative'\n",
    "\n",
    "    def __init__(self,\n",
    "                 units=32,\n",
    "                 attention_width=None,\n",
    "                 attention_type=ATTENTION_TYPE_ADD,\n",
    "                 return_attention=False,\n",
    "                 history_only=False,\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 use_additive_bias=True,\n",
    "                 use_attention_bias=True,\n",
    "                 attention_activation=None,\n",
    "                 attention_regularizer_weight=0.0,\n",
    "                 **kwargs):\n",
    "        \"\"\"Layer initialization.\n",
    "\n",
    "        For additive attention, see: https://arxiv.org/pdf/1806.01264.pdf\n",
    "\n",
    "        :param units: The dimension of the vectors that used to calculate the attention weights.\n",
    "        :param attention_width: The width of local attention.\n",
    "        :param attention_type: 'additive' or 'multiplicative'.\n",
    "        :param return_attention: Whether to return the attention weights for visualization.\n",
    "        :param history_only: Only use historical pieces of data.\n",
    "        :param kernel_initializer: The initializer for weight matrices.\n",
    "        :param bias_initializer: The initializer for biases.\n",
    "        :param kernel_regularizer: The regularization for weight matrices.\n",
    "        :param bias_regularizer: The regularization for biases.\n",
    "        :param kernel_constraint: The constraint for weight matrices.\n",
    "        :param bias_constraint: The constraint for biases.\n",
    "        :param use_additive_bias: Whether to use bias while calculating the relevance of inputs features\n",
    "                                  in additive mode.\n",
    "        :param use_attention_bias: Whether to use bias while calculating the weights of attention.\n",
    "        :param attention_activation: The activation used for calculating the weights of attention.\n",
    "        :param attention_regularizer_weight: The weights of attention regularizer.\n",
    "        :param kwargs: Parameters for parent class.\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.units = units\n",
    "        self.attention_width = attention_width\n",
    "        self.attention_type = attention_type\n",
    "        self.return_attention = return_attention\n",
    "        self.history_only = history_only\n",
    "        if history_only and attention_width is None:\n",
    "            self.attention_width = int(1e10)\n",
    "\n",
    "        self.use_additive_bias = use_additive_bias\n",
    "        self.use_attention_bias = use_attention_bias\n",
    "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = keras.initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n",
    "        self.kernel_constraint = keras.constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = keras.constraints.get(bias_constraint)\n",
    "        self.attention_activation = keras.activations.get(attention_activation)\n",
    "        self.attention_regularizer_weight = attention_regularizer_weight\n",
    "        self._backend = keras.backend.backend()\n",
    "\n",
    "        if attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            self.Wx, self.Wt, self.bh = None, None, None\n",
    "            self.Wa, self.ba = None, None\n",
    "        elif attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            self.Wa, self.ba = None, None\n",
    "        else:\n",
    "            raise NotImplementedError('No implementation for attention type : ' + attention_type)\n",
    "\n",
    "        super(SeqSelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'attention_width': self.attention_width,\n",
    "            'attention_type': self.attention_type,\n",
    "            'return_attention': self.return_attention,\n",
    "            'history_only': self.history_only,\n",
    "            'use_additive_bias': self.use_additive_bias,\n",
    "            'use_attention_bias': self.use_attention_bias,\n",
    "            'kernel_initializer': keras.regularizers.serialize(self.kernel_initializer),\n",
    "            'bias_initializer': keras.regularizers.serialize(self.bias_initializer),\n",
    "            'kernel_regularizer': keras.regularizers.serialize(self.kernel_regularizer),\n",
    "            'bias_regularizer': keras.regularizers.serialize(self.bias_regularizer),\n",
    "            'kernel_constraint': keras.constraints.serialize(self.kernel_constraint),\n",
    "            'bias_constraint': keras.constraints.serialize(self.bias_constraint),\n",
    "            'attention_activation': keras.activations.serialize(self.attention_activation),\n",
    "            'attention_regularizer_weight': self.attention_regularizer_weight,\n",
    "        }\n",
    "        base_config = super(SeqSelfAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            self._build_additive_attention(input_shape)\n",
    "        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            self._build_multiplicative_attention(input_shape)\n",
    "        super(SeqSelfAttention, self).build(input_shape)\n",
    "\n",
    "    def _build_additive_attention(self, input_shape):\n",
    "        feature_dim = input_shape[2]\n",
    "\n",
    "        self.Wt = self.add_weight(shape=(feature_dim, self.units),\n",
    "                                  name='{}_Add_Wt'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        self.Wx = self.add_weight(shape=(feature_dim, self.units),\n",
    "                                  name='{}_Add_Wx'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_additive_bias:\n",
    "            self.bh = self.add_weight(shape=(self.units,),\n",
    "                                      name='{}_Add_bh'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "        self.Wa = self.add_weight(shape=(self.units, 1),\n",
    "                                  name='{}_Add_Wa'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_attention_bias:\n",
    "            self.ba = self.add_weight(shape=(1,),\n",
    "                                      name='{}_Add_ba'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "    def _build_multiplicative_attention(self, input_shape):\n",
    "        feature_dim = input_shape[2]\n",
    "\n",
    "        self.Wa = self.add_weight(shape=(feature_dim, feature_dim),\n",
    "                                  name='{}_Mul_Wa'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_attention_bias:\n",
    "            self.ba = self.add_weight(shape=(1,),\n",
    "                                      name='{}_Mul_ba'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "    def call(self, inputs, mask=None, **kwargs):\n",
    "        if isinstance(inputs, list):\n",
    "            inputs, positions = inputs\n",
    "            positions = K.cast(positions, 'int32')\n",
    "            mask = mask[1]\n",
    "        else:\n",
    "            positions = None\n",
    "\n",
    "        input_len = K.shape(inputs)[1]\n",
    "\n",
    "        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            e = self._call_additive_emission(inputs)\n",
    "        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            e = self._call_multiplicative_emission(inputs)\n",
    "\n",
    "        if self.attention_activation is not None:\n",
    "            e = self.attention_activation(e)\n",
    "        e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
    "        if self.attention_width is not None:\n",
    "            ones = tf.ones((input_len, input_len))\n",
    "            if self.history_only:\n",
    "                local = tf.matrix_band_part(\n",
    "                    ones,\n",
    "                    K.minimum(input_len, self.attention_width - 1),\n",
    "                    0,\n",
    "                )\n",
    "            else:\n",
    "                local = tf.matrix_band_part(\n",
    "                    ones,\n",
    "                    K.minimum(input_len, self.attention_width // 2),\n",
    "                    K.minimum(input_len, (self.attention_width - 1) // 2),\n",
    "                )\n",
    "            e = e * K.expand_dims(local, 0)\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            mask = K.expand_dims(mask)\n",
    "            e = K.permute_dimensions(K.permute_dimensions(e * mask, (0, 2, 1)) * mask, (0, 2, 1))\n",
    "\n",
    "        # a_{t} = \\text{softmax}(e_t)\n",
    "        s = K.sum(e, axis=-1)\n",
    "        s = K.tile(K.expand_dims(s, axis=-1), K.stack([1, 1, input_len]))\n",
    "        a = e / (s + K.epsilon())\n",
    "\n",
    "        # l_t = \\sum_{t'} a_{t, t'} x_{t'}\n",
    "        v = K.batch_dot(a, inputs)\n",
    "        if self.attention_regularizer_weight > 0.0:\n",
    "            self.add_loss(self._attention_regularizer(a))\n",
    "\n",
    "        if positions is not None:\n",
    "            pos_num = K.shape(positions)[1]\n",
    "            batch_indices = K.tile(K.expand_dims(K.arange(K.shape(inputs)[0]), axis=-1), K.stack([1, pos_num]))\n",
    "            pos_indices = K.stack([batch_indices, positions], axis=-1)\n",
    "            v = tf.gather_nd(v, pos_indices)\n",
    "            a = tf.gather_nd(a, pos_indices)\n",
    "\n",
    "        if self.return_attention:\n",
    "            return [v, a]\n",
    "        return v\n",
    "\n",
    "    def _call_additive_emission(self, inputs):\n",
    "        input_shape = K.shape(inputs)\n",
    "        batch_size, input_len = input_shape[0], input_shape[1]\n",
    "\n",
    "        # h_{t, t'} = \\tanh(x_t^T W_t + x_{t'}^T W_x + b_h)\n",
    "        q, k = K.dot(inputs, self.Wt), K.dot(inputs, self.Wx)\n",
    "        q = K.tile(K.expand_dims(q, 2), K.stack([1, 1, input_len, 1]))\n",
    "        k = K.tile(K.expand_dims(k, 1), K.stack([1, input_len, 1, 1]))\n",
    "        if self.use_additive_bias:\n",
    "            h = K.tanh(q + k + self.bh)\n",
    "        else:\n",
    "            h = K.tanh(q + k)\n",
    "\n",
    "        # e_{t, t'} = W_a h_{t, t'} + b_a\n",
    "        if self.use_attention_bias:\n",
    "            e = K.reshape(K.dot(h, self.Wa) + self.ba, (batch_size, input_len, input_len))\n",
    "        else:\n",
    "            e = K.reshape(K.dot(h, self.Wa), (batch_size, input_len, input_len))\n",
    "        return e\n",
    "\n",
    "    def _call_multiplicative_emission(self, inputs):\n",
    "        # e_{t, t'} = x_t^T W_a x_{t'} + b_a\n",
    "        e = K.batch_dot(K.dot(inputs, self.Wa), K.permute_dimensions(inputs, (0, 2, 1)))\n",
    "        if self.use_attention_bias:\n",
    "            e = e + self.ba\n",
    "        return e\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape, pos_shape = input_shape\n",
    "            output_shape = (input_shape[0], pos_shape[1], input_shape[2])\n",
    "        else:\n",
    "            output_shape = input_shape\n",
    "        if self.return_attention:\n",
    "            attention_shape = (input_shape[0], output_shape[1], input_shape[1])\n",
    "            return [output_shape, attention_shape]\n",
    "        return output_shape\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if isinstance(inputs, list):\n",
    "            mask = mask[1]\n",
    "        if self.return_attention:\n",
    "            return [mask, None]\n",
    "        return mask\n",
    "\n",
    "    def _attention_regularizer(self, attention):\n",
    "        batch_size = K.cast(K.shape(attention)[0], K.floatx())\n",
    "        input_len = K.shape(attention)[-1]\n",
    "        return self.attention_regularizer_weight * K.sum(K.square(K.batch_dot(\n",
    "            attention,\n",
    "            K.permute_dimensions(attention, (0, 2, 1))) - tf.eye(input_len))) / batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def get_custom_objects():\n",
    "        return {'SeqSelfAttention': SeqSelfAttention}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "class SeqWeightedAttention(keras.layers.Layer):\n",
    "    \"\"\"Y = \\text{softmax}(XW + b) X\n",
    "    See: https://arxiv.org/pdf/1708.00524.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, use_bias=True, return_attention=False, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.use_bias = use_bias\n",
    "        self.return_attention = return_attention\n",
    "        self.W, self.b = None, None\n",
    "        super(SeqWeightedAttention, self).__init__(** kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'use_bias': self.use_bias,\n",
    "            'return_attention': self.return_attention,\n",
    "        }\n",
    "        base_config = super(SeqWeightedAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=keras.initializers.get('uniform'))\n",
    "        if self.use_bias:\n",
    "            self.b = self.add_weight(shape=(1,),\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     initializer=keras.initializers.get('zeros'))\n",
    "        super(SeqWeightedAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        logits = K.dot(x, self.W)\n",
    "        if self.use_bias:\n",
    "            logits += self.b\n",
    "        x_shape = K.shape(x)\n",
    "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
    "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            ai = ai * mask\n",
    "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
    "        weighted_input = x * K.expand_dims(att_weights)\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "        if self.return_attention:\n",
    "            return [result, att_weights]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_len = input_shape[2]\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
    "        return input_shape[0], output_len\n",
    "\n",
    "    def compute_mask(self, _, input_mask=None):\n",
    "        if self.return_attention:\n",
    "            return [None, None]\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_custom_objects():\n",
    "        return {'SeqWeightedAttention': SeqWeightedAttention}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 200, 100)          1300200   \n",
      "_________________________________________________________________\n",
      "seq_self_attention_2 (SeqSel (None, 200, 100)          6465      \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, 67)                45292     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 31)                2108      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 32        \n",
      "=================================================================\n",
      "Total params: 1,354,097\n",
      "Trainable params: 1,354,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model3():\n",
    "    model = models.Sequential()\n",
    "    model.add(Embedding(len(embedding_matrix), 100, input_length=200,  embeddings_regularizer=regularizers.l2(1e-6), weights = [embedding_matrix]))\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(CuDNNLSTM(67))\n",
    "    model.add(Dense(31))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam, loss='binary_crossentropy', metrics=['binary_crossentropy', 'accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 267212 samples, validate on 66804 samples\n",
      "Epoch 1/2\n",
      "267212/267212 [==============================] - 215s 806us/step - loss: 0.4491 - binary_crossentropy: 0.1972 - acc: 0.9197 - val_loss: 0.3351 - val_binary_crossentropy: 0.1579 - val_acc: 0.9375\n",
      "Epoch 2/2\n",
      "267212/267212 [==============================] - 216s 808us/step - loss: 0.2887 - binary_crossentropy: 0.1454 - acc: 0.9428 - val_loss: 0.2696 - val_binary_crossentropy: 0.1524 - val_acc: 0.9403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f624d975fd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, train_y, batch_size=250, epochs=2, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reset weights if necessary\n",
    "# model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust lr since val loss increases, seems to be going past minimum\n",
    "K.set_value(model.optimizer.lr, 0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 267212 samples, validate on 66804 samples\n",
      "Epoch 1/1\n",
      "267212/267212 [==============================] - 15s 56us/step - loss: 0.9735 - binary_crossentropy: 0.5589 - acc: 0.7529 - val_loss: 0.9732 - val_binary_crossentropy: 0.5587 - val_acc: 0.7531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff325085748>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, train_y, batch_size=500, epochs=1, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if re_run:\n",
    "    model.save('../../data/models/lstm.hdfs')\n",
    "else:\n",
    "    from keras.models import load_model\n",
    "    model = load_model('../../data/models/lstm.hdfs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.metrics_names)\n",
    "model.evaluate(val, val_y, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val, val_y, regression = False):\n",
    "    \n",
    "        \n",
    "    preds = model.predict(val)\n",
    "    #idx = np.random.randint(0, len(val_y), 5000)\n",
    "    pred_err = np.subtract(val_y.astype('float32'), preds.reshape(-1))\n",
    "    sns.distplot(pred_err)\n",
    "    plt.show()\n",
    "   \n",
    "    if regression:\n",
    "        rmse = np.sqrt(np.mean(pred_err**2))\n",
    "        print('rmse : %.4f' % rmse)\n",
    "    else:\n",
    "        cond_error = round((abs(pred_err) >= 0.5).sum()/len(pred_err), 4)\n",
    "        binary_cross_entropy = np.mean(\n",
    "                                        val_y * np.log(preds.reshape(-1)) + \\\n",
    "                                       (1-val_y) * np.log(1-preds.reshape(-1))\n",
    "        ) \n",
    "    \n",
    "        print('prob error is greater than 0.5 is %.4f' % cond_error)\n",
    "        print('binary cross entropy is %.4f' % binary_cross_entropy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(val, val_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
