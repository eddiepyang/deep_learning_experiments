{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import json\n",
    "import zipfile\n",
    "\n",
    "import spacy\n",
    "from gensim import corpora\n",
    "from gensim.models import tfidfmodel\n",
    "from gensim.matutils import corpus2csc\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "from collections import Counter, OrderedDict\n",
    "from os.path import expanduser\n",
    "import re, time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn.utils.rnn as rnn\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from itertools import zip_longest\n",
    "from operator import itemgetter\n",
    "\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import jsonlines as jsonl\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 2080 Ti'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_run = True\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(emb_path: str) -> dict:\n",
    "    \"\"\"load glove vectors\"\"\"\n",
    "    \n",
    "    embeddings_index={}\n",
    "    \n",
    "    with zipfile.ZipFile(expanduser(\"~\")+ emb_path +'glove.6B.zip', 'r') as f:\n",
    "        with f.open('glove.6B.100d.txt', 'r') as z:\n",
    "            for line in z:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                coefs = np.asarray(values[1:], dtype='float16')\n",
    "                embeddings_index[word] = coefs\n",
    "    \n",
    "    return embeddings_index\n",
    "\n",
    "def id_to_glove(dict_yelp: corpora.Dictionary, emb_path: str):\n",
    "    \n",
    "    \"\"\"converts local dictionary to embeddings from glove\"\"\"\n",
    "    \n",
    "    embeddings_index = load_embeddings(emb_path)\n",
    "    conversion_table = {}\n",
    "    \n",
    "    for word in dict_yelp.values():\n",
    "        if bytes(word, 'utf-8') in embeddings_index.keys():\n",
    "            conversion_table[dict_yelp.token2id[word]+1] = embeddings_index[bytes(word, 'utf-8')]\n",
    "        else:\n",
    "            conversion_table[dict_yelp.token2id[word]+1] = np.random.normal(0, .32, 100)\n",
    "            \n",
    "    embedding_matrix = np.vstack(\n",
    "        (\n",
    "            np.zeros(100), \n",
    "            list(conversion_table.values()), \n",
    "            np.random.randn(100)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return embedding_matrix\n",
    "\n",
    "def convert_rating(rating):\n",
    "    \n",
    "    \"\"\"moving ratings from 0 to 1\"\"\"\n",
    "    \n",
    "    if rating in [4,5]:\n",
    "        return 1\n",
    "    elif rating in [1,2]:\n",
    "        return 0\n",
    "\n",
    "def load_data(path: str, fname: str, stop: int = None) -> list:\n",
    "\n",
    "    \"reads from zipped yelp data file\"\n",
    "    \n",
    "    ls = []\n",
    "    with zipfile.ZipFile(path) as zfile:\n",
    "        print(zfile.namelist())\n",
    "        inf = zfile.open(fname)\n",
    "        with jsonl.Reader(inf) as file:\n",
    "            for i, line in enumerate(file):\n",
    "                line['text'] = tokenize(line.get('text'))\n",
    "                ls.append(line)\n",
    "                if stop and i == stop:\n",
    "                    break\n",
    "    return ls\n",
    "\n",
    "\n",
    "def text_sequencer(dictionary, text, max_len=200):\n",
    "    \n",
    "    \"\"\"converts tokens to numeric representation by dictionary\"\"\"\n",
    "    \n",
    "    processed = np.zeros(200, dtype=int)\n",
    "    # in case the word is not in the dictionary because it was filtered out use this number to represent an out of set id \n",
    "    dict_final = len(dictionary.keys()) + 1\n",
    "    \n",
    "    for i, word in enumerate(text):        \n",
    "        if i >= max_len:\n",
    "            return processed\n",
    "        if word in dictionary.token2id.keys():\n",
    "            # the ids have an offset of 1 for this because 0 represents a padded value        \n",
    "            processed[i] = dictionary.token2id[word] + 1\n",
    "        else:\n",
    "            processed[i] = dict_final\n",
    "    \n",
    "    return processed\n",
    "\n",
    "# regex tokenize, less accurate\n",
    "def tokenize(x): return re.findall('\\w+', x.lower())\n",
    "\n",
    "def load_data(path: str, fname: str, stop: int = None) -> list:\n",
    "    \"reads from zipped yelp data file\"\n",
    "    ls = []\n",
    "    with zipfile.ZipFile(path) as zfile:\n",
    "        print(zfile.namelist())\n",
    "        inf = zfile.open(fname)\n",
    "        with jsonl.Reader(inf) as file:\n",
    "            for i, line in enumerate(file):\n",
    "                line['text'] = tokenize(line.get('text'))\n",
    "                ls.append(line)\n",
    "                if stop and i == stop-1:\n",
    "                    break\n",
    "    return ls\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CorpusData(Dataset):\n",
    "    \n",
    "    \"\"\"Dataset class required for pytorch to output items by index\"\"\"\n",
    "    \n",
    "    test_size = 0.25\n",
    "    def __init__(\n",
    "        self, \n",
    "        fpath: str, \n",
    "        fname: str, \n",
    "        stop: int = None, \n",
    "        data: str = 'data',\n",
    "        labels: str = 'target', \n",
    "        test_size=0.25\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.fpath: str\n",
    "        self.fname: str\n",
    "        self.stop: int = None\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.dict_yelp: corpora.Dictionary = None\n",
    "        self.df: pd.DataFrame = self.parse_data(fpath, fname, stop)\n",
    "        self.test_size: float = test_size\n",
    "        self.tr_idx: list = None\n",
    "        self.val_idx: list = None\n",
    "        self.split_df()\n",
    "        \n",
    "    def parse_data(self, fpath, fname, stop):\n",
    "        \n",
    "        df = pd.DataFrame(load_data(fpath, fname, stop))\n",
    "        print('df loaded..')\n",
    "        self.dict_yelp = corpora.Dictionary(df.text)\n",
    "        self.dict_yelp.filter_extremes(no_below=10, no_above=.95, keep_n=30000)\n",
    "        print('dictionary created...')\n",
    "        df[self.data] = df.text.apply(lambda x: text_sequencer(self.dict_yelp, x))\n",
    "        df[self.labels] = df.stars.apply(convert_rating)\n",
    "        \n",
    "        return df.loc[df[self.labels].dropna()].reset_index(drop=True)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.__len__()\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        return self.df[self.data][i], self.df[self.labels][i]\n",
    "            \n",
    "    def split_df(self):\n",
    "        \n",
    "        self.tr_idx, self.val_idx = train_test_split(self.df.index.values, test_size = self.test_size)\n",
    "        return self\n",
    "    \n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.df.iloc[self.tr_idx]\n",
    "    \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.df.iloc[self.val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "gc.collect()\n",
    "fpath = '../data/archive.zip'\n",
    "fname = 'yelp_academic_dataset_review.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dataset_User_Agreement.pdf', 'yelp_academic_dataset_business.json', 'yelp_academic_dataset_checkin.json', 'yelp_academic_dataset_review.json', 'yelp_academic_dataset_tip.json', 'yelp_academic_dataset_user.json']\n",
      "df loaded..\n",
      "dictionary created...\n",
      "CPU times: user 1.95 s, sys: 40.1 ms, total: 1.99 s\n",
      "Wall time: 1.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = CorpusData(\n",
    "    fpath=fpath, \n",
    "    fname=fname, \n",
    "    stop=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 s, sys: 107 ms, total: 11.6 s\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embedding_matrix = id_to_glove(dataset.dict_yelp, '/projects/yelp_nlp/data/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_array(all_lens): \n",
    "    return np.unique(all_lens), np.bincount(all_lens), len(np.unique(all_lens)), len(np.bincount(all_lens))\n",
    "\n",
    "def resort_lens(idx, lens):\n",
    "    resorted_lenidx = np.array(sorted(zip(idx, lens), key=itemgetter(1), reverse=True))\n",
    "    return resorted_lenidx\n",
    "\n",
    "def resample_data(data, label, idx, lens):\n",
    "    \n",
    "        if isinstance(data, np.ndarray):\n",
    "            pass\n",
    "        else:\n",
    "            data= np.array(data)\n",
    "        assert len(data) == len(label)\n",
    "        sorted_ = resort_lens(idx, lens)\n",
    "        return data[sorted_[:,0]], label[sorted_[:,0]], sorted_[:,1]\n",
    "    \n",
    "#trainiter = iter(train_loader)\n",
    "\n",
    "def sort_lens(x, y, lens):\n",
    "    x=torch.stack(x,dim=1)\n",
    "    lens_, indices = lens.sort(descending=True)\n",
    "    x_, y_ = x[indices], y[indices]\n",
    "    return x_, y_, lens_\n",
    "\n",
    "def split(sorted_data, sorted_lab, all_lens, random_state=5):\n",
    "    \n",
    "    tr_idx, val_idx, tr_lens, val_lens = train_test_split(range(len(all_lens)), all_lens, \\\n",
    "                     test_size = 0.2, stratify=all_lens,\\\n",
    "                     random_state=random_state)\n",
    "    \n",
    "    train, train_y, tr_lens_ = resample_data(sorted_data, sorted_lab, tr_idx, tr_lens)\n",
    "    val, val_y, val_lens_ = resample_data(sorted_data, sorted_lab, val_idx, val_lens)\n",
    "    return {'train':[tr_idx, train, train_y, tr_lens_], 'val':[val_idx, val, val_y, val_lens_]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x, y, bsize):\n",
    "    \n",
    "    count = int(len(y)/bsize)+1\n",
    "    def convert(lsls):\n",
    "        return torch.stack([torch.tensor(ls) for ls in lsls])\n",
    "    for i in range(count):\n",
    "        a,b,c = len(y[i*bsize:(i+1)*bsize]), x[i*bsize:(i+1)*bsize], y[i*bsize:(i+1)*bsize]\n",
    "        yield a, convert(b), torch.tensor(c) \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    # weights are vocabsize x embedding length\n",
    "    def __init__(self, emb_weights, batch_size, input_len):\n",
    "    \n",
    "        super().__init__()\n",
    "        # vocab size in, hidden size out\n",
    "        self.batch_size = batch_size\n",
    "        self.embed_layer = nn.Embedding(emb_weights.shape[0], emb_weights.shape[1])\n",
    "        self.emb_weights = emb_weights\n",
    "        # input of shape (seq_len, batch, input_size) https://pytorch.org/docs/stable/nn.html\n",
    "        self.lstm = nn.LSTM(input_len, input_len)\n",
    "        \n",
    "        \"\"\"Input: (N, *, \\text{in\\_features})(N,∗,in_features) where *∗ means any number of additional dimensions\n",
    "        Output: (N, *, \\text{out\\_features})(N,∗,out_features) where all but the last dimension are the same shape as the input.\"\"\"\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_len,1)\n",
    "        self.fc2 = nn.Linear(emb_weights.shape[1], 1)\n",
    "        \n",
    "\n",
    "    def load_weights(self):\n",
    "        self.embed_layer.load_state_dict({'weight': self.emb_weights})\n",
    "        return self\n",
    "    \n",
    "    def forward(self, inputs, p=0.2, verbose=False):\n",
    "        \n",
    "        \n",
    "        embeds = self.embed_layer(inputs)\n",
    "        \n",
    "        nn.Dropout2d(p=p, inplace=True)(embeds)\n",
    "        \n",
    "        if verbose:\n",
    "            print('embedding shape %s' % (embeds.shape,))\n",
    "        \n",
    "        out, (hidden, cell) = self.lstm(embeds.permute(0,2,1))\n",
    "        \n",
    "        if verbose:\n",
    "            print('lstm out shape %s' % (out.shape,))\n",
    "        \n",
    "        out = F.relu(self.fc1(out))\n",
    "        if verbose:\n",
    "            print('fc1 out shape %s' % (out.shape,))\n",
    "        \n",
    "        fout = self.fc2(out.view(1,-1,100))\n",
    "        if verbose:\n",
    "            print('final %s' % (fout.shape,))\n",
    "        #prob = torch.sigmoid(fout)\n",
    "        \n",
    "        return fout.view(-1) \n",
    "    \n",
    "class RNNpacked(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_weights, batch_size, input_len):\n",
    " \n",
    "        super().__init__()\n",
    "        \n",
    "        # vocab size in, hidden size out\n",
    "        self.batch_size = batch_size\n",
    "        self.embed_layer = nn.Embedding(emb_weights.shape[0], emb_weights.shape[1])\n",
    "        self.emb_weights = emb_weights\n",
    "        self.dropout1 = nn.Dropout(p=0.5, inplace=True) \n",
    "        self.dropout3d1 = nn.Dropout3d(p=0.5, inplace=True)\n",
    "        self.dropout3d2 = nn.Dropout3d(p=0.5, inplace=True)\n",
    "        \n",
    "        # input of shape (seq_len, batch, input_size) https://pytorch.org/docs/stable/nn.html\n",
    "        self.lstm = nn.LSTM(emb_weights.shape[1], emb_weights.shape[1])\n",
    "        self.dropout2d1 = nn.Dropout2d(p=0.5, inplace=True)\n",
    "        self.dropout2d2 = nn.Dropout2d(p=0.5, inplace=True)\n",
    "        \n",
    "        \"\"\"Input: (N, *, \\text{in\\_features})(N,∗,in_features) where *∗ means any number of additional \n",
    "        dimensions Output: (N, *, \\text{out\\_features})(N,∗,out_features) where all but the last dimension \n",
    "        are the same shape as the input.\"\"\"\n",
    "        \n",
    "        self.fc1 = nn.Linear(emb_weights.shape[1], 1)\n",
    "        self.fc2 = nn.Linear(input_len,1)\n",
    "        \n",
    "    def load_weights(self):\n",
    "        self.embed_layer.load_state_dict({'weight': self.emb_weights})\n",
    "        return self\n",
    "    \n",
    "    def forward(self, inputs, input_lengths=None, verbose=False):\n",
    "        if verbose:\n",
    "            print('inputs', inputs.shape)\n",
    "            \n",
    "        #self.dropout1(inputs)\n",
    "        embeds = self.embed_layer(inputs)\n",
    "        if verbose:\n",
    "            print('embeds', embeds.shape)\n",
    "            print(embeds)\n",
    "        \n",
    "        #self.dropout3d1(embeds)\n",
    "        self.dropout2d1(embeds)\n",
    "        \n",
    "        if verbose:    \n",
    "            print(embeds)\n",
    "        packed = rnn.pack_padded_sequence(embeds, input_lengths, batch_first=True)\n",
    "        \n",
    "        if verbose:\n",
    "            print('packed', packed[0].shape)\n",
    "        out, (hidden, cell) = self.lstm(packed)\n",
    "        unpacked, lengths = rnn.pad_packed_sequence(out, total_length=200, batch_first=True)\n",
    "        \n",
    "        if verbose:\n",
    "            print('unpacked', unpacked.shape)\n",
    "        out = self.fc1(unpacked)\n",
    "        if verbose:\n",
    "            print('out', out.shape)\n",
    "        \n",
    "        self.dropout2d2(out)\n",
    "        #self.dropout3d2(out)\n",
    "        \n",
    "        fout = self.fc2(out.permute(0,2,1))\n",
    "        if verbose:\n",
    "            print('fout', fout.shape)\n",
    "        prob = F.sigmoid(fout)\n",
    "        \n",
    "        return fout.view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cuda'\n",
    "batch_size = 200\n",
    "input_len = 200\n",
    "emb_t = torch.from_numpy(embedding_matrix)\n",
    "emb = nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1])\n",
    "emb.load_state_dict({'weight': emb_t})\n",
    "model = RNN(emb_weights=emb_t, batch_size=batch_size, input_len=input_len)\n",
    "model.load_weights()\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.7, 0.99), weight_decay=1e-5)\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "# model_packed = RNNpacked(emb_weights=emb_t, batch_size=batch_size, input_len=input_len)\n",
    "# model_packed.load_weights()\n",
    "# model_packed.to(device)\n",
    "# optimizer = optim.Adam(model_packed.parameters(), lr=0.001)\n",
    "#torch.nn.utils.clip_grad_norm(mdl_sgd.parameters(),clip)\n",
    "\n",
    "def fit(model, loss_function, opitmizer, dataclass, batch_size, epochs, device, packed=False):\n",
    "    \n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    \n",
    "    epoch_count = 0\n",
    "    losses = []\n",
    "    train_loader = DataLoader(dataclass, batch_size=batch_size)\n",
    "\n",
    "    def train_epoch():\n",
    "        \n",
    "        nonlocal dataclass, train_loader, losses\n",
    "        \n",
    "        i=0\n",
    "        n=len(dataclass)\n",
    "        \n",
    "        for j, (sent, target) in enumerate(train_loader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "           \n",
    "            sent, labels = sent.long().to(device), target.float().to(device)\n",
    "            log_probs = model(sent)\n",
    "            #print(log_probs, labels)\n",
    "            loss = loss_function(log_probs, labels.to(device))\n",
    "            \n",
    "            # gets graident\n",
    "            loss.backward()\n",
    "            \n",
    "            # clips high gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.3, norm_type=2)\n",
    "            \n",
    "            # updates with new gradient\n",
    "            optimizer.step()\n",
    "            \n",
    "            i += len(labels)\n",
    "            #print(loss)\n",
    "            losses.append(loss.item())\n",
    "            if i % (batch_size*100) == 0:\n",
    "                print(f\"\"\"{i/n:.2f} of rows completed in {j+1} cycles, current loss at {np.mean(losses[-30:]):.4f}\"\"\" )\n",
    "\n",
    "    \n",
    "    print('fitting model...')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        train_epoch()\n",
    "        \n",
    "        epoch_count += 1\n",
    "        print(f'epoch {epoch_count} complete')\n",
    "    print(f'fit complete {time.time()-start:.0f} seconds passed')\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model...\n",
      "0.23 of rows completed in 100 cycles, current loss at 0.0106\n",
      "0.45 of rows completed in 200 cycles, current loss at 0.0057\n",
      "0.68 of rows completed in 300 cycles, current loss at 0.0034\n",
      "0.91 of rows completed in 400 cycles, current loss at 0.0020\n",
      "epoch 1 complete\n",
      "fit complete 10 seconds passed\n",
      "CPU times: user 9.58 s, sys: 19.1 ms, total: 9.6 s\n",
      "Wall time: 9.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# import pdb; pdb.set_trace()\n",
    "losses = fit(model, loss_function, optimizer, \n",
    "                    dataset, batch_size, 1, device=device, \n",
    "                    packed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "for item in optimizer.param_groups:\n",
    "    print(item['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "_ = plt.plot(losses)\n",
    "# plt.xlim(0, 500)\n",
    "# plt.ylim(0,.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7fb042f6a8b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorpusData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#val_loader = DataLoader(valcls, batch_size=250)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val' is not defined"
     ]
    }
   ],
   "source": [
    "valcls = CorpusData(data=val, labels=val_y)\n",
    "#val_loader = DataLoader(valcls, batch_size=250)\n",
    "\n",
    "def eval_model(model, valcls, loss_function, batch_size):\n",
    "    \n",
    "    val_loader = DataLoader(valcls, batch_size=batch_size)\n",
    "    preds = []; targets = []\n",
    "    with torch.no_grad():\n",
    "\n",
    "        model.eval()\n",
    "        for sent, target in val_loader:\n",
    "            #seqs, labels, lens_ = sort_lens(sent, target, lens)\n",
    "            #seqs = seqs.long().to(device)\n",
    "\n",
    "            res = model(sent.cuda())\n",
    "            \n",
    "            preds.append(res), targets.append(target)\n",
    "    \n",
    "    res = torch.cat(preds).cpu()\n",
    "    tru = torch.cat(targets).cpu()\n",
    "    \n",
    "    print(loss_function(res, tru.float()))    \n",
    "    \n",
    "\n",
    "    return res, tru\n",
    "\n",
    "preds, tru = eval_model(model, valcls, loss_function, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(true, preds, cutoff):\n",
    "    #preds = 1/(1+np.exp(-preds))\n",
    "    \n",
    "    res = np.greater(preds, np.array(cutoff))\n",
    "    recall = np.sum(res*true) / np.sum(true)\n",
    "    precision = np.sum(res*true) / np.sum(res)\n",
    "    return {'accuracy':round(np.mean(np.equal(true, res)), 4), 'precision': round(precision,4),\\\n",
    "            'recall': round(recall, 4), 'combined':round(precision*recall,4)}\n",
    "\n",
    "def get_reviewtext(row): \n",
    "    return ' '.join([dict_yelp[item-1] for item in traincls[row][0] if (item < 12589) and (item != 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val, val_y, regression = False):\n",
    "    \n",
    "        \n",
    "    preds = model.predict(val)\n",
    "    #idx = np.random.randint(0, len(val_y), 5000)\n",
    "    pred_err = np.subtract(val_y.astype('float32'), preds.reshape(-1))\n",
    "    sns.distplot(pred_err)\n",
    "    plt.show()\n",
    "   \n",
    "    if regression:\n",
    "        rmse = np.sqrt(np.mean(pred_err**2))\n",
    "        print('rmse : %.4f' % rmse)\n",
    "    else:\n",
    "        cond_error = round((abs(pred_err) >= 0.5).sum()/len(pred_err), 4)\n",
    "        binary_cross_entropy = np.mean(\n",
    "                                        val_y * np.log(preds.reshape(-1)) + \\\n",
    "                                       (1-val_y) * np.log(1-preds.reshape(-1))\n",
    "        ) \n",
    "    \n",
    "        print('prob error is greater than 0.5 is %.4f' % cond_error)\n",
    "        print('binary cross entropy is %.4f' % binary_cross_entropy)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
