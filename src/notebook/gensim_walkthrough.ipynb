{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import gensim\n",
    "import os\n",
    "import codecs\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.phrases import Phraser\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurant_ids1 = []\n",
    "\n",
    "# open the businesses file\n",
    "with open('./data/yelp_academic_dataset_business.json', encoding='utf_8') as f:\n",
    "    \n",
    "    # iterate through each line (json record) in the file\n",
    "    for line in f:\n",
    "        \n",
    "        # convert the json record to a Python dict\n",
    "        business = json.loads(line)\n",
    "        \n",
    "        # if this business is not a restaurant, skip to the next one\n",
    "        if business[\"categories\"] is not None and \"Restaurants\" in business[\"categories\"]:\n",
    "            # add the restaurant business id to our restaurant_ids set\n",
    "            restaurant_ids1.append({'id':business['business_id'], 'city':business['city'], \n",
    "                                    'state':business['state'], 'categories':business['categories']})\n",
    "        else:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurant_ids1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter([a for item in restaurant_ids1 for a in item['categories']]).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurant_ids1[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# restaurants = [{key: item[key]} for item in restaurant_ids1 for key in item.keys() if key in ['categories', 'id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "restaurants = []\n",
    "for item in restaurant_ids1:\n",
    "    tmp ={}\n",
    "    for key, val in item.items():\n",
    "        if key in ['categories', 'id']:\n",
    "          tmp[key] = val\n",
    "    restaurants.append(tmp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurants[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_json_filepath = os.path.join('./data/',\n",
    "                                    'yelp_academic_dataset_review.json')\n",
    "ids = [item['id'] for item in restaurant_ids1]\n",
    "\n",
    "rest_sample = np.random.choice(ids, 10000)\n",
    "\n",
    "rests = []\n",
    "with codecs.open(review_json_filepath, encoding='utf_8') as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        if review['business_id'] in rest_sample:\n",
    "            rests.append(review)\n",
    "        else:\n",
    "            continue\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the number of unique restaurant ids in the dataset\n",
    "\n",
    "print('{:,}'.format(len(restaurant_ids1)), u'restaurants in the dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking overlap in two methods\n",
    "missing = []\n",
    "with open('./data/yelp_academic_dataset_business.json', encoding='utf_8') as f:\n",
    "    \n",
    "    # iterate through each line (json record) in the file\n",
    "    for line in f:\n",
    "        business = json.loads(line)\n",
    "        if business['business_id'] in diff:\n",
    "            missing.append(business)\n",
    "            \n",
    "df = pd.DataFrame(missing)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(restaurants[0])\n",
    "rests[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "combined = []\n",
    "for item in rests:\n",
    "    for listing in restaurants:\n",
    "        if item['business_id']==listing['id']:\n",
    "            item['category'] = listing['categories']\n",
    "            combined.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "go = False\n",
    "if go == True:\n",
    "    with open('./data/processed.txt', 'w') as file:\n",
    "        for item in combined:\n",
    "            file.write(json.dumps(item) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load text\n",
    "rests = []\n",
    "with open('./processed/processed.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        rests.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def sentiment(question):\n",
    "    \n",
    "    pol_sub = [TextBlob(question).sentiment.polarity, \n",
    "               TextBlob(question).sentiment.subjectivity]\n",
    "    return pol_sub           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.089088713219148, 0.5837922705314009]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(rests[300]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reviews_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d3de3cec4ba8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'reviews_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "sentiment(' '.join(reviews_cleaned[300]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rests[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A one-star blah. This place will be"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nlp(rests[300]['text'])[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A one-star blah. This place will be closed down and forgotten before the coffee is served. Let me premise this by saying I'm not one of those usual review whiners that can't find anything good about anywhere. La Coupole was simply disappointing. \\n\\nWhen we walked in, I thought that it would be such a fine, impressive place to bring out-of-town, business guests. However, the food and service did not live up to the standards of the atmosphere and the hotel it's attached to. \\n\\nWe went as a group of about twelve guests for a business lunch today. A few of us ordered the catch of the day, which was the red snapper. However, it was so flavourless and tough that it tasted like the catch of yesterday. The parsnips that came with it were tasty though. Two people ordered the hanger steak, which presented beautifully and looked delicious, but they both said their meat was cold. \\nSome of the waitstaff were nice, one seemed very inexperienced and a couple of others seemed snooty and apathetic. One served my salad in front of me, then without asking if  I'd ordered it, took it away and gave it to someone else. I even stopped him to ask him why he was doing that, yet he ignored me and continued on serving it to the other individual. They only offered us coffee and tea after we were almost through dessert. \\n\\nI'll be recommending to my colleagues and friends that they go elsewhere. This town is too big for below average in a pricey `n pretty package.\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rests[300]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.15555555555555559, 0.2888888888888889]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(' '.join(clean_text(rests[300]['text']))[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03305555555555556, 0.5113888888888889]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(' '.join(clean_text(rests[300]['text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07442520442520444, 0.5651851851851851]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(' '.join(clean_text(rests[300]['text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business_id': '5RZt_9lrBSNDuzCyV1zPMw',\n",
       " 'category': ['Fish & Chips', 'Restaurants', 'Southern', 'Seafood'],\n",
       " 'cool': 1,\n",
       " 'date': '2013-03-26',\n",
       " 'funny': 0,\n",
       " 'review_id': 'zKsJsZ-UlU45UDdFacAXtQ',\n",
       " 'stars': 4,\n",
       " 'text': \"All I can say is, SO DELICIOUS!  I ordered the lunch special with the shrimp po'boy, fries, and a drink for around $6.50.  I took it to go, and it was still piping hot when I got back home 15 minutes later.  When I opened the container, fries came tumbling out, it was packed FULL!  I set them aside, and unwrapped the po'boy.  It was full of 3 large shrimp, fried crispy golden brown, lettuce, tomato, pickles, and sauce.  The bread was soft and fresh.  I added a little Louisiana Hot sauce and dug in!  It was amazing!  Such fresh flavors.  The fries were done perfectly, crisp on the outside, moist on the inside.  The iced tea is fresh brewed and nice and strong!  \\nDon't let the location keep you away.  The restaurant was immaculately clean, well lit with ample seating.  The young lady at the counter was pleasant and quick to get orders out when they came up.  Even when she was waiting for orders to be done, she was tidying up and making sure the restaurant was the way it should be.  A big plus was that she emptied the trash and IMMEDIATELY washed her hands even though she had an order up.  The orders are served in a closed container, but she still took the time to make sure her hands were clean.  You would think that would be a given, unfortunately it isn't.\\nA wonderful dining experience and I can't wait to share this restaurant with my family!\",\n",
       " 'type': 'review',\n",
       " 'useful': 1,\n",
       " 'user_id': 'OvBDMCz3QStF3vIdJIiuEQ'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rests[450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = [business['category'] for business in rests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490049"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.DataFrame(rests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_labels = set([item for category in categories for item in category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acai Bowls',\n",
       " 'Accountants',\n",
       " 'Active Life',\n",
       " 'Adult',\n",
       " 'Adult Entertainment',\n",
       " 'Afghan',\n",
       " 'African',\n",
       " 'Airport Lounges',\n",
       " 'Airport Shuttles',\n",
       " 'Airports',\n",
       " 'Amateur Sports Teams',\n",
       " 'American (New)',\n",
       " 'American (Traditional)',\n",
       " 'Amusement Parks',\n",
       " 'Apartments',\n",
       " 'Appliances',\n",
       " 'Aquarium Services',\n",
       " 'Aquariums',\n",
       " 'Arabian',\n",
       " 'Arcades',\n",
       " 'Argentine',\n",
       " 'Armenian',\n",
       " 'Art Galleries',\n",
       " 'Art Schools',\n",
       " 'Arts & Crafts',\n",
       " 'Arts & Entertainment',\n",
       " 'Asian Fusion',\n",
       " 'Australian',\n",
       " 'Austrian',\n",
       " 'Automotive',\n",
       " 'Bagels',\n",
       " 'Bakeries',\n",
       " 'Bangladeshi',\n",
       " 'Banks & Credit Unions',\n",
       " 'Barbeque',\n",
       " 'Barbers',\n",
       " 'Bars',\n",
       " 'Bartenders',\n",
       " 'Basque',\n",
       " 'Bavarian',\n",
       " 'Beach Bars',\n",
       " 'Beauty & Spas',\n",
       " 'Bed & Breakfast',\n",
       " 'Beer',\n",
       " 'Beer Bar',\n",
       " 'Beer Garden',\n",
       " 'Beer Gardens',\n",
       " 'Beer Hall',\n",
       " 'Belgian',\n",
       " 'Bike Repair/Maintenance',\n",
       " 'Bikes',\n",
       " 'Bistros',\n",
       " 'Books',\n",
       " 'Bookstores',\n",
       " 'Botanical Gardens',\n",
       " 'Bowling',\n",
       " 'Brasseries',\n",
       " 'Brazilian',\n",
       " 'Breakfast & Brunch',\n",
       " 'Breweries',\n",
       " 'British',\n",
       " 'Bubble Tea',\n",
       " 'Buffets',\n",
       " 'Building Supplies',\n",
       " 'Burgers',\n",
       " 'Burmese',\n",
       " 'Butcher',\n",
       " 'Cabaret',\n",
       " 'Cafes',\n",
       " 'Cafeteria',\n",
       " 'Cajun/Creole',\n",
       " 'Cambodian',\n",
       " 'Canadian (New)',\n",
       " 'Candy Stores',\n",
       " 'Cantonese',\n",
       " 'Car Dealers',\n",
       " 'Caribbean',\n",
       " 'Casinos',\n",
       " 'Caterers',\n",
       " 'Champagne Bars',\n",
       " 'Cheese Shops',\n",
       " 'Cheesesteaks',\n",
       " 'Chicken Shop',\n",
       " 'Chicken Wings',\n",
       " 'Chinese',\n",
       " 'Chiropractors',\n",
       " 'Chocolatiers & Shops',\n",
       " 'Churches',\n",
       " 'Cinema',\n",
       " 'Cocktail Bars',\n",
       " 'Coffee & Tea',\n",
       " 'Coffee Roasteries',\n",
       " 'Colombian',\n",
       " 'Comedy Clubs',\n",
       " 'Comfort Food',\n",
       " 'Community Centers',\n",
       " 'Contractors',\n",
       " 'Convenience Stores',\n",
       " 'Cooking Schools',\n",
       " 'Country Clubs',\n",
       " 'Country Dance Halls',\n",
       " 'Couriers & Delivery Services',\n",
       " 'Creperies',\n",
       " 'Cuban',\n",
       " 'Cultural Center',\n",
       " 'Cupcakes',\n",
       " 'Curry Sausage',\n",
       " 'Czech',\n",
       " 'Dance Clubs',\n",
       " 'Day Spas',\n",
       " 'Delicatessen',\n",
       " 'Delis',\n",
       " 'Department Stores',\n",
       " 'Desserts',\n",
       " 'Dim Sum',\n",
       " 'Diners',\n",
       " 'Dinner Theater',\n",
       " 'Distilleries',\n",
       " 'Dive Bars',\n",
       " 'Do-It-Yourself Food',\n",
       " 'Donairs',\n",
       " 'Donuts',\n",
       " 'Drive-Thru Bars',\n",
       " 'Drugstores',\n",
       " 'Eastern European',\n",
       " 'Education',\n",
       " 'Egyptian',\n",
       " 'Escape Games',\n",
       " 'Ethic Grocery',\n",
       " 'Ethiopian',\n",
       " 'Ethnic Food',\n",
       " 'Ethnic Grocery',\n",
       " 'Event Planning & Services',\n",
       " 'Falafel',\n",
       " 'Farmers Market',\n",
       " 'Fashion',\n",
       " 'Fast Food',\n",
       " 'Feng Shui',\n",
       " 'Festivals',\n",
       " 'Filipino',\n",
       " 'Financial Advising',\n",
       " 'Financial Services',\n",
       " 'Fish & Chips',\n",
       " 'Fitness & Instruction',\n",
       " 'Flea Markets',\n",
       " 'Florists',\n",
       " 'Flowers & Gifts',\n",
       " 'Fondue',\n",
       " 'Food',\n",
       " 'Food Court',\n",
       " 'Food Delivery Services',\n",
       " 'Food Stands',\n",
       " 'Food Trucks',\n",
       " 'French',\n",
       " 'Fruits & Veggies',\n",
       " 'Funeral Services & Cemeteries',\n",
       " 'Gas & Service Stations',\n",
       " 'Gastropubs',\n",
       " 'Gay Bars',\n",
       " 'Gelato',\n",
       " 'German',\n",
       " 'Gift Shops',\n",
       " 'Gluten-Free',\n",
       " 'Golf',\n",
       " 'Golf Lessons',\n",
       " 'Greek',\n",
       " 'Grocery',\n",
       " 'Guest Houses',\n",
       " 'Gyms',\n",
       " 'Hainan',\n",
       " 'Hair Removal',\n",
       " 'Hair Salons',\n",
       " 'Hair Stylists',\n",
       " 'Hakka',\n",
       " 'Halal',\n",
       " 'Hawaiian',\n",
       " 'Health & Medical',\n",
       " 'Health Markets',\n",
       " 'Heating & Air Conditioning/HVAC',\n",
       " 'Herbs & Spices',\n",
       " 'Himalayan/Nepalese',\n",
       " 'Hobby Shops',\n",
       " 'Home & Garden',\n",
       " 'Home Decor',\n",
       " 'Home Services',\n",
       " 'Hong Kong Style Cafe',\n",
       " 'Hookah Bars',\n",
       " 'Hot Dogs',\n",
       " 'Hot Pot',\n",
       " 'Hotel bar',\n",
       " 'Hotels',\n",
       " 'Hotels & Travel',\n",
       " 'Hungarian',\n",
       " 'Ice Cream & Frozen Yogurt',\n",
       " 'Imported Food',\n",
       " 'Indian',\n",
       " 'Indonesian',\n",
       " 'Insurance',\n",
       " 'International',\n",
       " 'International Grocery',\n",
       " 'Internet Cafes',\n",
       " 'Irish',\n",
       " 'Irish Pub',\n",
       " 'Italian',\n",
       " 'Japanese',\n",
       " 'Jazz & Blues',\n",
       " 'Juice Bars & Smoothies',\n",
       " 'Karaoke',\n",
       " 'Kebab',\n",
       " 'Keys & Locksmiths',\n",
       " 'Kids Activities',\n",
       " 'Kitchen & Bath',\n",
       " 'Korean',\n",
       " 'Kosher',\n",
       " 'Landmarks & Historical Buildings',\n",
       " 'Laotian',\n",
       " 'Laser Hair Removal',\n",
       " 'Laser Tag',\n",
       " 'Latin American',\n",
       " 'Lebanese',\n",
       " 'Leisure Centers',\n",
       " 'Libraries',\n",
       " 'Limos',\n",
       " 'Live/Raw Food',\n",
       " 'Local Fish Stores',\n",
       " 'Local Flavor',\n",
       " 'Local Services',\n",
       " 'Lounges',\n",
       " 'Macarons',\n",
       " 'Mags',\n",
       " 'Malaysian',\n",
       " 'Marketing',\n",
       " 'Martial Arts',\n",
       " 'Meat Shops',\n",
       " 'Medical Centers',\n",
       " 'Medical Spas',\n",
       " 'Mediterranean',\n",
       " \"Men's Clothing\",\n",
       " 'Mexican',\n",
       " 'Middle Eastern',\n",
       " 'Mini Golf',\n",
       " 'Modern European',\n",
       " 'Mongolian',\n",
       " 'Moroccan',\n",
       " 'Mortgage Brokers',\n",
       " 'Museums',\n",
       " 'Music & Video',\n",
       " 'Music Venues',\n",
       " 'Nail Salons',\n",
       " 'New Mexican Cuisine',\n",
       " 'Nightlife',\n",
       " 'Noodles',\n",
       " 'Nutritionists',\n",
       " 'Organic Stores',\n",
       " 'Oriental',\n",
       " 'Pakistani',\n",
       " 'Pan Asian',\n",
       " 'Parks',\n",
       " 'Party & Event Planning',\n",
       " 'Party Bus Rentals',\n",
       " 'Pasta Shops',\n",
       " 'Patisserie/Cake Shop',\n",
       " 'Pawn Shops',\n",
       " 'Performing Arts',\n",
       " 'Persian/Iranian',\n",
       " 'Personal Assistants',\n",
       " 'Personal Chefs',\n",
       " 'Peruvian',\n",
       " 'Pet Services',\n",
       " 'Pet Stores',\n",
       " 'Pets',\n",
       " 'Piano Bars',\n",
       " 'Piercing',\n",
       " 'Pita',\n",
       " 'Pizza',\n",
       " 'Plumbing',\n",
       " 'Poke',\n",
       " 'Polish',\n",
       " 'Pool Halls',\n",
       " 'Portuguese',\n",
       " 'Poutineries',\n",
       " 'Pretzels',\n",
       " 'Professional Services',\n",
       " 'Pub Food',\n",
       " 'Public Services & Government',\n",
       " 'Pubs',\n",
       " 'Puerto Rican',\n",
       " 'Ramen',\n",
       " 'Real Estate',\n",
       " 'Recreation Centers',\n",
       " 'Religious Organizations',\n",
       " 'Resorts',\n",
       " 'Restaurants',\n",
       " 'Russian',\n",
       " 'Sailing',\n",
       " 'Salad',\n",
       " 'Salvadoran',\n",
       " 'Sandwiches',\n",
       " 'Scandinavian',\n",
       " 'Scottish',\n",
       " 'Seafood',\n",
       " 'Seafood Markets',\n",
       " 'Septic Services',\n",
       " 'Serbo Croatian',\n",
       " 'Shanghainese',\n",
       " 'Shared Office Spaces',\n",
       " 'Shaved Ice',\n",
       " 'Shopping',\n",
       " 'Shopping Centers',\n",
       " 'Singaporean',\n",
       " 'Skin Care',\n",
       " 'Smokehouse',\n",
       " 'Soccer',\n",
       " 'Social Clubs',\n",
       " 'Soul Food',\n",
       " 'Soup',\n",
       " 'South African',\n",
       " 'Southern',\n",
       " 'Spanish',\n",
       " 'Speakeasies',\n",
       " 'Special Education',\n",
       " 'Specialty Food',\n",
       " 'Specialty Schools',\n",
       " 'Sporting Goods',\n",
       " 'Sports Bars',\n",
       " 'Sports Clubs',\n",
       " 'Sri Lankan',\n",
       " 'Steakhouses',\n",
       " 'Street Vendors',\n",
       " 'Supper Clubs',\n",
       " 'Sushi Bars',\n",
       " 'Swabian',\n",
       " 'Swimming Pools',\n",
       " 'Swiss Food',\n",
       " 'Szechuan',\n",
       " 'Tacos',\n",
       " 'Taiwanese',\n",
       " 'Tanning',\n",
       " 'Tapas Bars',\n",
       " 'Tapas/Small Plates',\n",
       " 'Tattoo',\n",
       " 'Tax Services',\n",
       " 'Taxis',\n",
       " 'Tea Rooms',\n",
       " 'Teppanyaki',\n",
       " 'Tex-Mex',\n",
       " 'Thai',\n",
       " 'Themed Cafes',\n",
       " 'Ticket Sales',\n",
       " 'Tiki Bars',\n",
       " 'Tobacco Shops',\n",
       " 'Tours',\n",
       " 'Toy Stores',\n",
       " 'Transportation',\n",
       " 'Travel Services',\n",
       " 'Trinidadian',\n",
       " 'Turkish',\n",
       " 'Ukrainian',\n",
       " 'Vape Shops',\n",
       " 'Vegan',\n",
       " 'Vegetarian',\n",
       " 'Venezuelan',\n",
       " 'Venues & Event Spaces',\n",
       " 'Videos & Video Game Rental',\n",
       " 'Vietnamese',\n",
       " 'Vinyl Records',\n",
       " 'Vitamins & Supplements',\n",
       " 'Waffles',\n",
       " 'Water Heater Installation/Repair',\n",
       " 'Waxing',\n",
       " 'Web Design',\n",
       " 'Wedding Planning',\n",
       " 'Weight Loss Centers',\n",
       " 'Whiskey Bars',\n",
       " 'Wholesale Stores',\n",
       " 'Wigs',\n",
       " 'Wine & Spirits',\n",
       " 'Wine Bars',\n",
       " 'Wineries',\n",
       " \"Women's Clothing\",\n",
       " 'Wraps',\n",
       " 'Yelp Events',\n",
       " 'Zoos'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_data = [list(x) for x in set(tuple(x) for x in categories)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4953"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490049, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    # Remove HTML\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    \n",
    "    #removes numbers, symbols, nextline symbols \n",
    "    \n",
    "    text = re.sub(\"[^a-zA-Z'0-9]\",\" \", str(text))\n",
    "    text = text.replace(\"\\n\", '').replace('  ', ' ').lower().strip('.')\n",
    "    text = nlp(text)\n",
    "    \n",
    "    # removes punctuation and pronouns, returns lemmatized word\n",
    "    lex = nlp.vocab['not']\n",
    "    lex.is_stop = False\n",
    "    \n",
    "    words=[]\n",
    "    for word in text:\n",
    "        if word.pos_ != 'PUNCT' and not word.is_space and word.lemma_ !='-PRON-':\n",
    "            words.append(word.lemma_)\n",
    "\n",
    "    \n",
    "    unigrams = [word for word in words if word not in ['t', 's', \"v\", \"'s\" \"n't\", 'food'\n",
    "                                                      ]\n",
    "               ]\n",
    "    if len(unigrams) > 200:\n",
    "        unigrams = unigrams[0:50] + unigrams[-50:]\n",
    "    return unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE CLASSIC BURGER IS AMAZING.  It's definitely a top ten burger. The fries are good too.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"the classic burger is amazing  it's definitely a top ten burger the fries are good too\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = reviews['text'][5]\n",
    "samp_text = re.sub(\"[^a-zA-Z' ]\", \" \", str(text))\n",
    "samp_text = samp_text.replace(\"\\n\\n\", '').lower().strip().replace('  ', ' ').split('. ')\n",
    "print(text)\n",
    "samp_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             word    pos   tag      lemma          orth\n",
      "0               A    DET    DT          a             A\n",
      "1             one    NUM    CD        one           one\n",
      "2               -  PUNCT  HYPH          -             -\n",
      "3            star   NOUN    NN       star          star\n",
      "4            blah   NOUN    NN       blah          blah\n",
      "5               .  PUNCT     .          .             .\n",
      "6            This    DET    DT       this          This\n",
      "7           place   NOUN    NN      place         place\n",
      "8            will   VERB    MD       will          will\n",
      "9              be   VERB    VB         be            be\n",
      "10         closed   VERB   VBN      close        closed\n",
      "11           down    ADV    RB       down          down\n",
      "12            and  CCONJ    CC        and           and\n",
      "13      forgotten   VERB   VBN     forget     forgotten\n",
      "14         before    ADP    IN     before        before\n",
      "15            the    DET    DT        the           the\n",
      "16         coffee   NOUN    NN     coffee        coffee\n",
      "17             is   VERB   VBZ         be            is\n",
      "18         served   VERB   VBN      serve        served\n",
      "19              .  PUNCT     .          .             .\n",
      "20            Let   VERB    VB        let           Let\n",
      "21             me   PRON   PRP     -PRON-            me\n",
      "22        premise   VERB    VB    premise       premise\n",
      "23           this    DET    DT       this          this\n",
      "24             by    ADP    IN         by            by\n",
      "25         saying   VERB   VBG        say        saying\n",
      "26              I   PRON   PRP     -PRON-             I\n",
      "27             'm   VERB   VBP         be            'm\n",
      "28            not    ADV    RB        not           not\n",
      "29            one    NUM    CD        one           one\n",
      "..            ...    ...   ...        ...           ...\n",
      "279             I   PRON   PRP     -PRON-             I\n",
      "280           'll   VERB    MD       will           'll\n",
      "281            be   VERB    VB         be            be\n",
      "282  recommending   VERB   VBG  recommend  recommending\n",
      "283            to    ADP    IN         to            to\n",
      "284            my    ADJ  PRP$     -PRON-            my\n",
      "285    colleagues   NOUN   NNS  colleague    colleagues\n",
      "286           and  CCONJ    CC        and           and\n",
      "287       friends   NOUN   NNS     friend       friends\n",
      "288          that    ADP    IN       that          that\n",
      "289          they   PRON   PRP     -PRON-          they\n",
      "290            go   VERB   VBP         go            go\n",
      "291     elsewhere    ADV    RB  elsewhere     elsewhere\n",
      "292             .  PUNCT     .          .             .\n",
      "293          This    DET    DT       this          This\n",
      "294          town   NOUN    NN       town          town\n",
      "295            is   VERB   VBZ         be            is\n",
      "296           too    ADV    RB        too           too\n",
      "297           big    ADJ    JJ        big           big\n",
      "298           for    ADP    IN        for           for\n",
      "299         below    ADP    IN      below         below\n",
      "300       average    ADJ    JJ    average       average\n",
      "301            in    ADP    IN         in            in\n",
      "302             a    DET    DT          a             a\n",
      "303        pricey    ADJ    JJ     pricey        pricey\n",
      "304             `   NOUN   NNS          `             `\n",
      "305             n  CCONJ    CC          n             n\n",
      "306        pretty    ADJ    JJ     pretty        pretty\n",
      "307       package   NOUN    NN    package       package\n",
      "308             .  PUNCT     .          .             .\n",
      "\n",
      "[309 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "test = nlp(rests[300]['text'])\n",
    "print(pd.DataFrame([(word, word.pos_, word.tag_, word.lemma_, word.orth_) for word in test], columns = ['word', 'pos', 'tag', 'lemma', 'orth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classic', 'burger', 'amazing', 'be', 'definitely', 'burger', 'fry', 'good']\n"
     ]
    }
   ],
   "source": [
    "print(clean_text(reviews['text'][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50min 40s, sys: 3.75 s, total: 50min 44s\n",
      "Wall time: 50min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "reviews_cleaned = [clean_text(review['text']) for review in rests]\n",
    "#reviews_cleaned = reviews['text'].apply(clean_text)\n",
    "len(reviews_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "go = True\n",
    "if go == True:\n",
    "    with open(\"reviews_cleaned.txt\", \"w\") as f:\n",
    "        for line in reviews_cleaned:\n",
    "            f.write(json.dumps(line) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3933333333333333, 0.4333333333333334]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(' '.join(reviews_cleaned[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rests[5]['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3933333333333333, 0.4333333333333334]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(rests[5]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## start from here for next run\n",
    "with open(\"./processed/stuff.txt\", \"r\") as test:\n",
    "    reviews_cleaned =[]\n",
    "    for line in test:\n",
    "        reviews_cleaned.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['place',\n",
       " 'area',\n",
       " 'staple',\n",
       " 'year',\n",
       " 'not',\n",
       " 'change',\n",
       " 'good',\n",
       " 'thing',\n",
       " 'stable',\n",
       " 'reliable',\n",
       " 'family',\n",
       " 'go',\n",
       " 'year',\n",
       " 'st',\n",
       " 'patty',\n",
       " 'day',\n",
       " 'corn',\n",
       " 'beef',\n",
       " 'nice',\n",
       " 'place',\n",
       " 'bar',\n",
       " 'night',\n",
       " 'dinner',\n",
       " 'catch',\n",
       " 'friend',\n",
       " 'drink']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "\n",
    "#unigrams = [review.split(' ') for review in reviews_cleaned]\n",
    "unigrams = reviews_cleaned\n",
    "reviews_cleaned[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490049"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigrams = gensim.models.phrases.Phraser(Phrases(unigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_sents = []\n",
    "for sent in unigrams:\n",
    "   bigram_sents.append(bigrams[sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigrams = Phrases(bigram_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryeyoo/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:315: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trigram_sents =''\n",
    "for bigram in bigram_sents:\n",
    "    trigram_sents += ' '.join(trigrams[bigram])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#span = re.search('mastro_', trigram_sents).span()\n",
    "#print(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trigram_sents[span[0]:span[1]+500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryeyoo/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:315: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "trigram_phrases = [trigrams[bigram] for bigram in bigram_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "multigram_list = re.findall(r'\\w*_\\w*_\\w*', trigram_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sweet_potato_fry', 3472),\n",
       " ('mac_n_cheese', 2400),\n",
       " ('seat_right_away', 1838),\n",
       " ('http_www_yelp_com', 1167),\n",
       " ('french_onion_soup', 1075),\n",
       " ('hot_sour_soup', 995),\n",
       " ('corn_beef_hash', 948),\n",
       " ('pull_pork_sandwich', 868),\n",
       " ('soft_shell_crab', 786),\n",
       " ('staff_friendly_helpful', 695),\n",
       " ('lobster_mac_cheese', 693),\n",
       " ('vanilla_ice_cream', 594),\n",
       " ('staff_friendly_attentive', 589),\n",
       " ('creme_br_l_e', 579),\n",
       " ('beef_noodle_soup', 574),\n",
       " ('chicken_tikka_masala', 566),\n",
       " ('pico_de_gallo', 539),\n",
       " ('sweet_sour_chicken', 533),\n",
       " ('thin_crust_pizza', 530),\n",
       " ('thai_iced_tea', 519)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(multigram_list).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'place area staple year not change good thing stable reliable family go year st_patty day corn_beef nice place bar night dinner catch friend drinkget mojo have appetite teaser love lpw frill bite eatnot decor staff_friendly fried_pickle tasty good valuebelieve award_star bear_mind type restaurant rev'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_sents[0:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('not', 735793),\n",
       " ('good', 475121),\n",
       " ('be', 356141),\n",
       " ('place', 330352),\n",
       " ('order', 249294),\n",
       " ('great', 229119),\n",
       " ('like', 213606),\n",
       " ('come', 211187),\n",
       " ('time', 197166),\n",
       " ('service', 185463),\n",
       " ('try', 152945),\n",
       " ('restaurant', 144547),\n",
       " ('get', 133677),\n",
       " ('go', 133172),\n",
       " ('eat', 127944),\n",
       " ('have', 123350),\n",
       " ('love', 110385),\n",
       " ('nice', 96988),\n",
       " ('menu', 95375),\n",
       " ('want', 87835)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([word for line in trigram_phrases for word in line]).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(214051 unique tokens: ['place', 'area', 'staple', 'year', 'not']...)\n"
     ]
    }
   ],
   "source": [
    "trigram_dictionary = Dictionary(trigram_phrases)\n",
    "print(trigram_dictionary)\n",
    "#print(trigram_dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214051"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trigram_dictionary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# must give doc2bow the tokenized list from trigrams\n",
    "corpus_yelp = [trigram_dictionary.doc2bow(phrase) for phrase in trigram_phrases]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_yelp = models.TfidfModel(corpus_yelp)\n",
    "tfidf_corpus = tfidf_yelp[corpus_yelp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#lda = LdaMulticore(corpus_yelp, num_topics = 20, id2word=trigram_dictionary, workers = 6, chunksize=10000, passes=2)\n",
    "\n",
    "lda = gensim.models.ldamodel.LdaModel(corpus=tfidf_corpus, id2word=trigram_dictionary, num_topics=20, update_every=1, chunksize=10000, passes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda.show_topics(num_topics=-1, num_words=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lda_description(review_text, min_topic_freq=0.05):\n",
    "    \"\"\"\n",
    "    accept the original text of a review and (1) parse it with spaCy,\n",
    "    (2) apply text pre-proccessing steps, (3) create a bag-of-words\n",
    "    representation, (4) create an LDA representation, and\n",
    "    (5) print a sorted list of the top topics in the LDA representation\n",
    "    \"\"\"\n",
    "    \n",
    "    # parse the review text with spaCy\n",
    "    #parsed_review = nlp(review_text)\n",
    "    \n",
    "    # lemmatize the text and remove punctuation and whitespace\n",
    "    unigram_review = clean_text(review_text)\n",
    "    \n",
    "    # apply the first-order and secord-order phrase models\n",
    "    bigram_review = bigrams[unigram_review]\n",
    "    trigram_review = trigrams[bigram_review]\n",
    "    \n",
    "    # remove any remaining stopwords\n",
    "    trigram_review = [term for term in trigram_review\n",
    "                      if not term in spacy.en.language_data.STOP_WORDS]\n",
    "    \n",
    "    # create a bag-of-words representation\n",
    "    review_bow = trigram_dictionary.doc2bow(trigram_review)\n",
    "    \n",
    "    # create an LDA representation\n",
    "    review_lda = lda[review_bow]\n",
    "    \n",
    "    # sort with the most highly related topics first\n",
    "    review_lda = sorted(review_lda, key=lambda top_freq: (top_freq[0], top_freq[1]))\n",
    "    \n",
    "    for topic_number, freq in review_lda:\n",
    "        if freq < min_topic_freq:\n",
    "            break\n",
    "            \n",
    "        #print the most highly related topic names and frequencies\n",
    "        #print (\"{!s:25s}\".format((topic_number, round(freq, 3))))\n",
    "        print ((topic_number, round(freq, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(lda_description(reviews['text'][250]))\n",
    "reviews['text'][250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda.print_topic(9)\n",
    "lda.print_topic(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lda.save('yelp_lda')\n",
    "\n",
    "yelp_lda = gensim.models.ldamodel.LdaModel.load('yelp_lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LDAvis_prepared = pyLDAvis.gensim.prepare(yelp_lda, tfidf_corpus,\n",
    "                                              trigram_dictionary)\n",
    "pyLDAvis.display(LDAvis_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x= reviews['stars'], y = reviews['stars'], estimator= lambda x: len(x)/len(reviews['stars']))\n",
    "plt.ylabel('proportion')\n",
    "plt.show()\n",
    "\n",
    "sns.distplot(np.log(reviews['funny'].value_counts()))\n",
    "plt.xlim(0,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent semantic analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsi = gensim.models.lsimodel.LsiModel(corpus=tfidf_corpus, id2word=trigram_dictionary, num_topics=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsi.print_topics(12, num_words = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(trigram_phrases[10])\n",
    "\n",
    "review = lsi[trigram_dictionary.doc2bow(trigram_phrases[10])]\n",
    "\n",
    "sorted([topic for topic in review if topic[1] > .05], key = lambda topic: topic[1], reverse = True)[0:5]\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2vec = gensim.models.Word2Vec(trigram_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2vec.save(\"./models/review_vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(w2vec.similarity('france', 'america'))\n",
    "\n",
    "w2vec.most_similar(positive=['lunch_special', 'bad'], negative=['burger'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rpy2.interactive as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext rmagic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libicuuc.so.54: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1b4dfa2bb75d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrpy2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# import R's \"base\" package\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/rpy2/robjects/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mrpy2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrinterface\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrinterface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrpy2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrlike\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrlc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/rpy2/rinterface/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m from rpy2.rinterface._rinterface import (baseenv,\n\u001b[0m\u001b[1;32m     51\u001b[0m                                          \u001b[0memptyenv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                                          \u001b[0mendr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libicuuc.so.54: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "# import R's \"base\" package\n",
    "base = importr('base')\n",
    "\n",
    "# import R's \"utils\" package\n",
    "utils = importr('utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
