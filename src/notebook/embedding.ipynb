{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import json\n",
    "import zipfile as zip\n",
    "\n",
    "import spacy\n",
    "from keras.preprocessing import text, sequence\n",
    "from gensim import corpora\n",
    "from gensim.models import tfidfmodel\n",
    "from gensim.matutils import corpus2csc\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "from collections import Counter, OrderedDict\n",
    "from os.path import expanduser\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras import models, optimizers, regularizers\n",
    "from keras.layers import Dropout, Dense, Activation, Flatten, LSTM, \\\n",
    "Conv1D, MaxPooling1D, GRU, Embedding, CuDNNLSTM, Bidirectional\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is preprocessed as a list of lists, reviews are parsed and stop words and punctuation are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_run = False\n",
    "\n",
    "if re_run:\n",
    "    # processed from gensim_walkthrough notebook\n",
    "    with open('../../data/processed/processed.txt', 'r') as f:\n",
    "        restaurants = tuple(json.loads(line) for line in f)\n",
    "\n",
    "    # different text cleaning for reviews\n",
    "    with open('../../data/processed/reviews_cleaned.txt', 'r') as f:\n",
    "        reviews = tuple(json.loads(line) for line in f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras text processing example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if re_run:\n",
    "    tokenizer = text.Tokenizer()\n",
    "    tokenizer.fit_on_texts(reviews[0])\n",
    "    tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing the same process with gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skipping a step by not creating two dictionaries for train and test, they get recombined anyway for an update of new data though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000\n",
      "CPU times: user 3.74 ms, sys: 7.89 ms, total: 11.6 ms\n",
      "Wall time: 11.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if re_run:\n",
    "    \n",
    "    # create dictionary\n",
    "    dict_yelp = corpora.Dictionary(reviews)\n",
    "    # tune corpus to get a smaller dictionary and therefore a smaller doc_term matrix, \n",
    "    # embeddings will still work but bow will not fit into 8gb gpu otherwise\n",
    "    dict_yelp.filter_extremes(no_below=10, keep_n=13000)\n",
    "    dict_yelp.save('../../data/processed/dictionary')\n",
    "\n",
    "else:\n",
    "    \n",
    "    dict_yelp = corpora.Dictionary.load('../../data/processed/dictionary')\n",
    "\n",
    "print(len(dict_yelp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if re_run:\n",
    "    # most common words\n",
    "    top_ids = sorted(dict_yelp.dfs.items(), key=lambda x: x[1], reverse=True)[0:30]\n",
    "    [(dict_yelp[item[0]], item[1]) for item in top_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_sequencer(dictionary, text, max_len=200):\n",
    "    \n",
    "    processed = []\n",
    "    # in case the word is not in the dictionary because it was filtered out use this number to represent an out of set id \n",
    "    dict_final = len(dictionary.keys()) + 1\n",
    "    \n",
    "    for word in text:        \n",
    "        if word in dictionary.token2id.keys():\n",
    "    # remember the ids have an offset of 1 for this because 0 represents a padded value        \n",
    "            processed.append(dictionary.token2id[word] + 1) \n",
    "        else:\n",
    "            processed.append(dict_final)\n",
    "    \n",
    "    return processed[0:max_len]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.63 ms, sys: 115 ms, total: 118 ms\n",
      "Wall time: 118 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if re_run:\n",
    "    \n",
    "    corpus = tuple(text_sequencer(dict_yelp, review) for review in reviews)\n",
    "    corpus = sequence.pad_sequences(corpus, maxlen=200)\n",
    "    assert corpus.shape == (490049, 200)\n",
    "    # this is the converted corpus array, not bow\n",
    "    np.save('../../data/processed/corpus.npy', corpus)\n",
    "\n",
    "else:\n",
    "    corpus = np.load('../../data/processed/corpus.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(emb_path = '/projects/embeddings/data/'):\n",
    "    # load glove vectors\n",
    "    embeddings_index={}\n",
    "    with zip.ZipFile(expanduser(\"~\")+ emb_path +'glove.6B.zip', 'r') as f:\n",
    "        with f.open('glove.6B.100d.txt', 'r') as z:\n",
    "            for line in z:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                coefs = np.asarray(values[1:], dtype='float32')\n",
    "                embeddings_index[word] = coefs\n",
    "    \n",
    "    return embeddings_index\n",
    "\n",
    "def id_to_glove(keys, dict_yelp):\n",
    "    \n",
    "    embeddings_index = load_embeddings()\n",
    "    conversion_table = {}\n",
    "    for key in keys:\n",
    "        if bytes(key, 'utf-8') in embeddings_index.keys():\n",
    "            conversion_table[dict_yelp.token2id[key]+1] = embeddings_index[bytes(key, 'utf-8')]\n",
    "        else:\n",
    "            conversion_table[dict_yelp.token2id[key]+1] = np.random.randn(100)\n",
    "    return conversion_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.3 s, sys: 201 ms, total: 16.5 s\n",
      "Wall time: 16.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conversion_table = id_to_glove(dict_yelp.token2id.keys(), dict_yelp)\n",
    "embedding_matrix= np.vstack(conversion_table.values())\n",
    "embedding_matrix = np.vstack((np.zeros(100), embedding_matrix, np.random.randn(100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rating(rating):\n",
    "    if rating in [4,5]:\n",
    "        return 1\n",
    "    elif rating in [1,2]:\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_rating_set(corpus, stars):\n",
    "    \n",
    "    \n",
    "    mids = set()\n",
    "    \n",
    "    def get_mids():\n",
    "\n",
    "        for i, rating in enumerate(stars):\n",
    "            if rating is None:\n",
    "                mids.add(i)\n",
    "    \n",
    "    get_mids()\n",
    "    filtered_corpus, filtered_stars = [], []\n",
    "    \n",
    "    for i in range(len(corpus)):\n",
    "        if i in mids:\n",
    "            next\n",
    "        else:\n",
    "            filtered_corpus.append(corpus[i]), filtered_stars.append(stars[i])\n",
    "    \n",
    "    return filtered_corpus, filtered_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if re_run:\n",
    "    stars = [convert_rating(restaurant['stars']) for restaurant in restaurants]\n",
    "    data, lab = get_rating_set(corpus, stars)\n",
    "    with open('../../data/numpy/ratings.npy', 'wb') as outf:\n",
    "        np.save(outf, lab)\n",
    "    with open('../../data/numpy/corpus.npy', 'wb') as outf:\n",
    "        np.save(outf, data)\n",
    "else:\n",
    "    data, lab = np.load('../../data/numpy/corpus.npy'), np.load('../../data/numpy/ratings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, train_y, val_y = train_test_split(data, lab, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryeyoo/miniconda3/envs/keras/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x = lab, y = lab, estimator=lambda x: len(x)/len(lab))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(dict_yelp)\n",
    "Adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# units for output size in Dense layer, vocab_size for number of features in nlp in Embedding \n",
    "# tried adding dropout but it lowered accuracy, shouldn't need it if it's not overfitting\n",
    "def get_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(Embedding(len(embedding_matrix), 100, input_length=200,  embeddings_regularizer=regularizers.l2(1e-6), weights = [embedding_matrix]))\n",
    "    model.add(Conv1D(100, 5))\n",
    "    model.add(Conv1D(100, 3))\n",
    "    model.add(MaxPooling1D(4))\n",
    "    model.add(LSTM(67))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model2():\n",
    "    model = models.Sequential()\n",
    "    model.add(Embedding(len(embedding_matrix), 100, input_length=200,  embeddings_regularizer=regularizers.l2(1e-6), weights = [embedding_matrix]))\n",
    "    model.add(Bidirectional(CuDNNLSTM(67, return_sequences = True)))\n",
    "    model.add(Bidirectional(CuDNNLSTM(67)))\n",
    "    model.add(Dense(31))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model3():\n",
    "    model = models.Sequential()\n",
    "    model.add(Embedding(len(embedding_matrix), 100, input_length=200,  embeddings_regularizer=regularizers.l2(1e-6), weights = [embedding_matrix]))\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(CuDNNLSTM(67))\n",
    "    model.add(Dense(31))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['binary_crossentropy', 'accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SeqSelfAttention at 0x7f6ce5e753c8>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SeqSelfAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 200, 100)          1300200   \n",
      "_________________________________________________________________\n",
      "seq_self_attention_5 (SeqSel (None, 200, 100)          6465      \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_4 (CuDNNLSTM)     (None, 67)                45292     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 31)                2108      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 32        \n",
      "=================================================================\n",
      "Total params: 1,354,097\n",
      "Trainable params: 1,354,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f6ce5e75eb8>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import merge\n",
    "from keras.layers.core import *\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "?Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class ScaledDotProductAttention(keras.layers.Layer):\n",
    "    \"\"\"The attention layer that takes three inputs representing queries, keys and values.\n",
    "\n",
    "    \\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{Q K^T}{\\sqrt{d_k}}) V\n",
    "\n",
    "    See: https://arxiv.org/pdf/1706.03762.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 return_attention=False,\n",
    "                 history_only=False,\n",
    "                 **kwargs):\n",
    "        \"\"\"Initialize the layer.\n",
    "\n",
    "        :param return_attention: Whether to return attention weights.\n",
    "        :param history_only: Whether to only use history data.\n",
    "        :param kwargs: Arguments for parent class.\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        self.history_only = history_only\n",
    "        super(ScaledDotProductAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'return_attention': self.return_attention,\n",
    "            'history_only': self.history_only,\n",
    "        }\n",
    "        base_config = super(ScaledDotProductAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_attention:\n",
    "            return [input_shape[-1], input_shape[0][:2] + (input_shape[1][1],)]\n",
    "        return input_shape[-1]\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[-1]\n",
    "        if self.return_attention:\n",
    "            return [mask, None]\n",
    "        return mask\n",
    "\n",
    "    def call(self, inputs, mask=None, **kwargs):\n",
    "        query, key, value = inputs\n",
    "        feature_dim = K.shape(query)[-1]\n",
    "        e = K.batch_dot(query, key, axes=2) / K.sqrt(K.cast(feature_dim, dtype=K.floatx()))\n",
    "        if self.history_only:\n",
    "            query_len, key_len = K.shape(query)[1], K.shape(key)[1]\n",
    "            ones = tf.ones((query_len, key_len))\n",
    "            e -= (ones - tf.matrix_band_part(ones, -1, 0)) * 1e9\n",
    "        if isinstance(mask, list) and mask[-1] is not None:\n",
    "            e -= (1.0 - K.cast(K.expand_dims(mask[-1], axis=-2), K.floatx())) * 1e9\n",
    "        a = keras.activations.softmax(e)\n",
    "        v = K.batch_dot(a, value)\n",
    "        if self.return_attention:\n",
    "            return [v, a]\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class SeqSelfAttention(keras.layers.Layer):\n",
    "\n",
    "    ATTENTION_TYPE_ADD = 'additive'\n",
    "    ATTENTION_TYPE_MUL = 'multiplicative'\n",
    "\n",
    "    def __init__(self,\n",
    "                 units=32,\n",
    "                 attention_width=None,\n",
    "                 attention_type=ATTENTION_TYPE_ADD,\n",
    "                 return_attention=False,\n",
    "                 history_only=False,\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 use_additive_bias=True,\n",
    "                 use_attention_bias=True,\n",
    "                 attention_activation=None,\n",
    "                 attention_regularizer_weight=0.0,\n",
    "                 **kwargs):\n",
    "        \"\"\"Layer initialization.\n",
    "\n",
    "        For additive attention, see: https://arxiv.org/pdf/1806.01264.pdf\n",
    "\n",
    "        :param units: The dimension of the vectors that used to calculate the attention weights.\n",
    "        :param attention_width: The width of local attention.\n",
    "        :param attention_type: 'additive' or 'multiplicative'.\n",
    "        :param return_attention: Whether to return the attention weights for visualization.\n",
    "        :param history_only: Only use historical pieces of data.\n",
    "        :param kernel_initializer: The initializer for weight matrices.\n",
    "        :param bias_initializer: The initializer for biases.\n",
    "        :param kernel_regularizer: The regularization for weight matrices.\n",
    "        :param bias_regularizer: The regularization for biases.\n",
    "        :param kernel_constraint: The constraint for weight matrices.\n",
    "        :param bias_constraint: The constraint for biases.\n",
    "        :param use_additive_bias: Whether to use bias while calculating the relevance of inputs features\n",
    "                                  in additive mode.\n",
    "        :param use_attention_bias: Whether to use bias while calculating the weights of attention.\n",
    "        :param attention_activation: The activation used for calculating the weights of attention.\n",
    "        :param attention_regularizer_weight: The weights of attention regularizer.\n",
    "        :param kwargs: Parameters for parent class.\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.units = units\n",
    "        self.attention_width = attention_width\n",
    "        self.attention_type = attention_type\n",
    "        self.return_attention = return_attention\n",
    "        self.history_only = history_only\n",
    "        if history_only and attention_width is None:\n",
    "            self.attention_width = int(1e10)\n",
    "\n",
    "        self.use_additive_bias = use_additive_bias\n",
    "        self.use_attention_bias = use_attention_bias\n",
    "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = keras.initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n",
    "        self.kernel_constraint = keras.constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = keras.constraints.get(bias_constraint)\n",
    "        self.attention_activation = keras.activations.get(attention_activation)\n",
    "        self.attention_regularizer_weight = attention_regularizer_weight\n",
    "        self._backend = keras.backend.backend()\n",
    "\n",
    "        if attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            self.Wx, self.Wt, self.bh = None, None, None\n",
    "            self.Wa, self.ba = None, None\n",
    "        elif attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            self.Wa, self.ba = None, None\n",
    "        else:\n",
    "            raise NotImplementedError('No implementation for attention type : ' + attention_type)\n",
    "\n",
    "        super(SeqSelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'attention_width': self.attention_width,\n",
    "            'attention_type': self.attention_type,\n",
    "            'return_attention': self.return_attention,\n",
    "            'history_only': self.history_only,\n",
    "            'use_additive_bias': self.use_additive_bias,\n",
    "            'use_attention_bias': self.use_attention_bias,\n",
    "            'kernel_initializer': keras.regularizers.serialize(self.kernel_initializer),\n",
    "            'bias_initializer': keras.regularizers.serialize(self.bias_initializer),\n",
    "            'kernel_regularizer': keras.regularizers.serialize(self.kernel_regularizer),\n",
    "            'bias_regularizer': keras.regularizers.serialize(self.bias_regularizer),\n",
    "            'kernel_constraint': keras.constraints.serialize(self.kernel_constraint),\n",
    "            'bias_constraint': keras.constraints.serialize(self.bias_constraint),\n",
    "            'attention_activation': keras.activations.serialize(self.attention_activation),\n",
    "            'attention_regularizer_weight': self.attention_regularizer_weight,\n",
    "        }\n",
    "        base_config = super(SeqSelfAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            self._build_additive_attention(input_shape)\n",
    "        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            self._build_multiplicative_attention(input_shape)\n",
    "        super(SeqSelfAttention, self).build(input_shape)\n",
    "\n",
    "    def _build_additive_attention(self, input_shape):\n",
    "        feature_dim = input_shape[2]\n",
    "\n",
    "        self.Wt = self.add_weight(shape=(feature_dim, self.units),\n",
    "                                  name='{}_Add_Wt'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        self.Wx = self.add_weight(shape=(feature_dim, self.units),\n",
    "                                  name='{}_Add_Wx'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_additive_bias:\n",
    "            self.bh = self.add_weight(shape=(self.units,),\n",
    "                                      name='{}_Add_bh'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "        self.Wa = self.add_weight(shape=(self.units, 1),\n",
    "                                  name='{}_Add_Wa'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_attention_bias:\n",
    "            self.ba = self.add_weight(shape=(1,),\n",
    "                                      name='{}_Add_ba'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "    def _build_multiplicative_attention(self, input_shape):\n",
    "        feature_dim = input_shape[2]\n",
    "\n",
    "        self.Wa = self.add_weight(shape=(feature_dim, feature_dim),\n",
    "                                  name='{}_Mul_Wa'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_attention_bias:\n",
    "            self.ba = self.add_weight(shape=(1,),\n",
    "                                      name='{}_Mul_ba'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "    def call(self, inputs, mask=None, **kwargs):\n",
    "        if isinstance(inputs, list):\n",
    "            inputs, positions = inputs\n",
    "            positions = K.cast(positions, 'int32')\n",
    "            mask = mask[1]\n",
    "        else:\n",
    "            positions = None\n",
    "\n",
    "        input_len = K.shape(inputs)[1]\n",
    "\n",
    "        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            e = self._call_additive_emission(inputs)\n",
    "        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            e = self._call_multiplicative_emission(inputs)\n",
    "\n",
    "        if self.attention_activation is not None:\n",
    "            e = self.attention_activation(e)\n",
    "        e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
    "        if self.attention_width is not None:\n",
    "            ones = tf.ones((input_len, input_len))\n",
    "            if self.history_only:\n",
    "                local = tf.matrix_band_part(\n",
    "                    ones,\n",
    "                    K.minimum(input_len, self.attention_width - 1),\n",
    "                    0,\n",
    "                )\n",
    "            else:\n",
    "                local = tf.matrix_band_part(\n",
    "                    ones,\n",
    "                    K.minimum(input_len, self.attention_width // 2),\n",
    "                    K.minimum(input_len, (self.attention_width - 1) // 2),\n",
    "                )\n",
    "            e = e * K.expand_dims(local, 0)\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            mask = K.expand_dims(mask)\n",
    "            e = K.permute_dimensions(K.permute_dimensions(e * mask, (0, 2, 1)) * mask, (0, 2, 1))\n",
    "\n",
    "        # a_{t} = \\text{softmax}(e_t)\n",
    "        s = K.sum(e, axis=-1)\n",
    "        s = K.tile(K.expand_dims(s, axis=-1), K.stack([1, 1, input_len]))\n",
    "        a = e / (s + K.epsilon())\n",
    "\n",
    "        # l_t = \\sum_{t'} a_{t, t'} x_{t'}\n",
    "        v = K.batch_dot(a, inputs)\n",
    "        if self.attention_regularizer_weight > 0.0:\n",
    "            self.add_loss(self._attention_regularizer(a))\n",
    "\n",
    "        if positions is not None:\n",
    "            pos_num = K.shape(positions)[1]\n",
    "            batch_indices = K.tile(K.expand_dims(K.arange(K.shape(inputs)[0]), axis=-1), K.stack([1, pos_num]))\n",
    "            pos_indices = K.stack([batch_indices, positions], axis=-1)\n",
    "            v = tf.gather_nd(v, pos_indices)\n",
    "            a = tf.gather_nd(a, pos_indices)\n",
    "\n",
    "        if self.return_attention:\n",
    "            return [v, a]\n",
    "        return v\n",
    "\n",
    "    def _call_additive_emission(self, inputs):\n",
    "        input_shape = K.shape(inputs)\n",
    "        batch_size, input_len = input_shape[0], input_shape[1]\n",
    "\n",
    "        # h_{t, t'} = \\tanh(x_t^T W_t + x_{t'}^T W_x + b_h)\n",
    "        q, k = K.dot(inputs, self.Wt), K.dot(inputs, self.Wx)\n",
    "        q = K.tile(K.expand_dims(q, 2), K.stack([1, 1, input_len, 1]))\n",
    "        k = K.tile(K.expand_dims(k, 1), K.stack([1, input_len, 1, 1]))\n",
    "        if self.use_additive_bias:\n",
    "            h = K.tanh(q + k + self.bh)\n",
    "        else:\n",
    "            h = K.tanh(q + k)\n",
    "\n",
    "        # e_{t, t'} = W_a h_{t, t'} + b_a\n",
    "        if self.use_attention_bias:\n",
    "            e = K.reshape(K.dot(h, self.Wa) + self.ba, (batch_size, input_len, input_len))\n",
    "        else:\n",
    "            e = K.reshape(K.dot(h, self.Wa), (batch_size, input_len, input_len))\n",
    "        return e\n",
    "\n",
    "    def _call_multiplicative_emission(self, inputs):\n",
    "        # e_{t, t'} = x_t^T W_a x_{t'} + b_a\n",
    "        e = K.batch_dot(K.dot(inputs, self.Wa), K.permute_dimensions(inputs, (0, 2, 1)))\n",
    "        if self.use_attention_bias:\n",
    "            e = e + self.ba\n",
    "        return e\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape, pos_shape = input_shape\n",
    "            output_shape = (input_shape[0], pos_shape[1], input_shape[2])\n",
    "        else:\n",
    "            output_shape = input_shape\n",
    "        if self.return_attention:\n",
    "            attention_shape = (input_shape[0], output_shape[1], input_shape[1])\n",
    "            return [output_shape, attention_shape]\n",
    "        return output_shape\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if isinstance(inputs, list):\n",
    "            mask = mask[1]\n",
    "        if self.return_attention:\n",
    "            return [mask, None]\n",
    "        return mask\n",
    "\n",
    "    def _attention_regularizer(self, attention):\n",
    "        batch_size = K.cast(K.shape(attention)[0], K.floatx())\n",
    "        input_len = K.shape(attention)[-1]\n",
    "        return self.attention_regularizer_weight * K.sum(K.square(K.batch_dot(\n",
    "            attention,\n",
    "            K.permute_dimensions(attention, (0, 2, 1))) - tf.eye(input_len))) / batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def get_custom_objects():\n",
    "        return {'SeqSelfAttention': SeqSelfAttention}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "class SeqWeightedAttention(keras.layers.Layer):\n",
    "    \"\"\"Y = \\text{softmax}(XW + b) X\n",
    "    See: https://arxiv.org/pdf/1708.00524.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, use_bias=True, return_attention=False, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.use_bias = use_bias\n",
    "        self.return_attention = return_attention\n",
    "        self.W, self.b = None, None\n",
    "        super(SeqWeightedAttention, self).__init__(** kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'use_bias': self.use_bias,\n",
    "            'return_attention': self.return_attention,\n",
    "        }\n",
    "        base_config = super(SeqWeightedAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=keras.initializers.get('uniform'))\n",
    "        if self.use_bias:\n",
    "            self.b = self.add_weight(shape=(1,),\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     initializer=keras.initializers.get('zeros'))\n",
    "        super(SeqWeightedAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        logits = K.dot(x, self.W)\n",
    "        if self.use_bias:\n",
    "            logits += self.b\n",
    "        x_shape = K.shape(x)\n",
    "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
    "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            ai = ai * mask\n",
    "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
    "        weighted_input = x * K.expand_dims(att_weights)\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "        if self.return_attention:\n",
    "            return [result, att_weights]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_len = input_shape[2]\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
    "        return input_shape[0], output_len\n",
    "\n",
    "    def compute_mask(self, _, input_mask=None):\n",
    "        if self.return_attention:\n",
    "            return [None, None]\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_custom_objects():\n",
    "        return {'SeqWeightedAttention': SeqWeightedAttention}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 200, 100)          1300200   \n",
      "_________________________________________________________________\n",
      "seq_self_attention_7 (SeqSel (None, 200, 100)          6465      \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_6 (CuDNNLSTM)     (None, 67)                45292     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 31)                2108      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 32        \n",
      "=================================================================\n",
      "Total params: 1,354,097\n",
      "Trainable params: 1,354,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model3():\n",
    "    model = models.Sequential()\n",
    "    model.add(Embedding(len(embedding_matrix), 100, input_length=200,  embeddings_regularizer=regularizers.l2(1e-6), weights = [embedding_matrix]))\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(CuDNNLSTM(67))\n",
    "    model.add(Dense(31))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam, loss='binary_crossentropy', metrics=['binary_crossentropy', 'accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 267212 samples, validate on 66804 samples\n",
      "Epoch 1/2\n",
      "267212/267212 [==============================] - 233s 872us/step - loss: 0.4354 - binary_crossentropy: 0.2086 - acc: 0.9144 - val_loss: 0.3105 - val_binary_crossentropy: 0.1581 - val_acc: 0.9369\n",
      "Epoch 2/2\n",
      "267212/267212 [==============================] - 230s 859us/step - loss: 0.2705 - binary_crossentropy: 0.1480 - acc: 0.9419 - val_loss: 0.2528 - val_binary_crossentropy: 0.1526 - val_acc: 0.9393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6c900d3be0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, train_y, batch_size=200, epochs=2, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reset weights if necessary\n",
    "# model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust lr since val loss increases, seems to be going past minimum\n",
    "K.set_value(model.optimizer.lr, 0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 267212 samples, validate on 66804 samples\n",
      "Epoch 1/1\n",
      "267212/267212 [==============================] - 211s 789us/step - loss: 0.2273 - binary_crossentropy: 0.1335 - acc: 0.9483 - val_loss: 0.2390 - val_binary_crossentropy: 0.1513 - val_acc: 0.9403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6c900d39b0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, train_y, batch_size=500, epochs=1, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if re_run:\n",
    "    model.save('../../data/models/lstm.hdfs')\n",
    "else:\n",
    "    from keras.models import load_model\n",
    "    model = load_model('../../data/models/lstm.hdfs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'binary_crossentropy', 'acc']\n",
      "83504/83504 [==============================] - 15s 182us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26366071798468393, 0.13044080564457425, 0.9503017819505652]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "model.evaluate(val, val_y, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val, val_y, regression = False):\n",
    "    \n",
    "        \n",
    "    preds = model.predict(val)\n",
    "    #idx = np.random.randint(0, len(val_y), 5000)\n",
    "    pred_err = np.subtract(val_y.astype('float32'), preds.reshape(-1))\n",
    "    sns.distplot(pred_err)\n",
    "    plt.show()\n",
    "   \n",
    "    if regression:\n",
    "        rmse = np.sqrt(np.mean(pred_err**2))\n",
    "        print('rmse : %.4f' % rmse)\n",
    "    else:\n",
    "        cond_error = round((abs(pred_err) >= 0.5).sum()/len(pred_err), 4)\n",
    "        binary_cross_entropy = np.mean(\n",
    "                                        val_y * np.log(preds.reshape(-1)) + \\\n",
    "                                       (1-val_y) * np.log(1-preds.reshape(-1))\n",
    "        ) \n",
    "    \n",
    "        print('prob error is greater than 0.5 is %.4f' % cond_error)\n",
    "        print('binary cross entropy is %.4f' % binary_cross_entropy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob error is greater than 0.5 is 0.0497\n",
      "binary cross entropy is -0.1304\n"
     ]
    }
   ],
   "source": [
    "evaluate(val, val_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
